{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Argo Events - The Event-driven Workflow Automation Framework What is Argo Events? Argo Events is an event-driven workflow automation framework for Kubernetes which helps you trigger K8s objects, Argo Workflows, Serverless workloads, etc. on events from variety of sources like webhook, s3, schedules, messaging queues, gcp pubsub, sns, sqs, etc. Features Supports events from 20+ event sources. Ability to customize business-level constraint logic for workflow automation. Manage everything from simple, linear, real-time to complex, multi-source events. Supports Kubernetes Objects, Argo Workflow, AWS Lambda, Serverless, etc. as triggers. CloudEvents compliant. Getting Started Follow these instruction to set up Argo Events. Documentation Concepts . Argo Events in action . Deep dive into Argo Events . Triggers Argo Workflows Standard K8s Objects HTTP Requests / Serverless Workloads (OpenFaas, Kubeless, KNative etc.) AWS Lambda NATS Messages Kafka Messages Slack Notifications Argo Rollouts Custom Trigger / Build Your Own Trigger Apache OpenWhisk Event Sources Argo-Events supports 20+ event sources. The complete list of event sources is available here . Who uses Argo Events? Organizations below are officially using Argo Events. Please send a PR with your organization name if you are using Argo Events. BioBox Analytics BlackRock Canva Fairwinds InsideBoard Intuit Viaduct Community Blogs and Presentations Automating Research Workflows at BlackRock Designing A Complete CI/CD Pipeline CI/CD Pipeline Using Argo Events, Workflows, and CD TGI Kubernetes with Joe Beda: CloudEvents and Argo Events","title":"Overview"},{"location":"#argo-events-the-event-driven-workflow-automation-framework","text":"","title":"Argo Events - The Event-driven Workflow Automation Framework"},{"location":"#what-is-argo-events","text":"Argo Events is an event-driven workflow automation framework for Kubernetes which helps you trigger K8s objects, Argo Workflows, Serverless workloads, etc. on events from variety of sources like webhook, s3, schedules, messaging queues, gcp pubsub, sns, sqs, etc.","title":"What is Argo Events?"},{"location":"#features","text":"Supports events from 20+ event sources. Ability to customize business-level constraint logic for workflow automation. Manage everything from simple, linear, real-time to complex, multi-source events. Supports Kubernetes Objects, Argo Workflow, AWS Lambda, Serverless, etc. as triggers. CloudEvents compliant.","title":"Features"},{"location":"#getting-started","text":"Follow these instruction to set up Argo Events.","title":"Getting Started"},{"location":"#documentation","text":"Concepts . Argo Events in action . Deep dive into Argo Events .","title":"Documentation"},{"location":"#triggers","text":"Argo Workflows Standard K8s Objects HTTP Requests / Serverless Workloads (OpenFaas, Kubeless, KNative etc.) AWS Lambda NATS Messages Kafka Messages Slack Notifications Argo Rollouts Custom Trigger / Build Your Own Trigger Apache OpenWhisk","title":"Triggers"},{"location":"#event-sources","text":"Argo-Events supports 20+ event sources. The complete list of event sources is available here .","title":"Event Sources"},{"location":"#who-uses-argo-events","text":"Organizations below are officially using Argo Events. Please send a PR with your organization name if you are using Argo Events. BioBox Analytics BlackRock Canva Fairwinds InsideBoard Intuit Viaduct","title":"Who uses Argo Events?"},{"location":"#community-blogs-and-presentations","text":"Automating Research Workflows at BlackRock Designing A Complete CI/CD Pipeline CI/CD Pipeline Using Argo Events, Workflows, and CD TGI Kubernetes with Joe Beda: CloudEvents and Argo Events","title":"Community Blogs and Presentations"},{"location":"FAQ/","text":"FAQs Q. How to get started with Argo Events? A . Recommended way to get started with Argo Events is, Read the basic concepts about EventBus , Sensor and Event Source . Install the setup as outlined here . Read the tutorials available here . Q. Can I deploy event-source and sensor in a namespace different that argo-events ? A . Yes. If you want to deploy the event-source in a different namespace that argo-events , then please update the event-source definition with desired namespace and service account. Make sure to grant the service account the necessary roles. Q. How to debug Argo-Events. A . Make sure you have installed everything as instructed here . Make sure you have EventBus resource created in the namespace. The event-bus, event-source and sensor pods must be running. If you see any issue with the pods, check the logs for sensor-controller, event-source-controller or event-bus-controller. If event-source and sensor pods are running, but you are not receiving any events: Make sure you have configured the event source correctly. Check the logs of the event-source pod's containers. Note: You can set environment variable DEBUG_LOG:true in any of the containers to output debug logs. Q. Event-source pod is receiving the events but nothing happens. A . Check the sensor resource is deployed and a pod is running for the resource. If sensor pod is running, check for the logs that says Started to subscribe events for triggers . If the sensor has subscribed to the event-bus but unable to create the trigger resource, raise an issue on GitHub. Q. Helm chart installation does not work. A. The helm chart for argo events is maintained by the community and can be out of sync with latest release version. The official installation file is available here . If you notice the helm chart is outdated, we encourage you to contribute to the argo-helm . Q. Kustomization file doesn't have a X resource. A. The kustomization.yaml file is maintained by the community. If you notice that it is out of sync with the official installation file, please raise a PR. Q. Can I use Minio event-source for AWS S3 notifications? A. No. Minio event-source is exclusive for the Minio server. If you want to trigger workloads on AWS S3 bucket notification, then set up the AWS SNS event-source. Q. If I have multiple event dependencies and triggers in a single sensor, can I execute a specific trigger upon a specific event? A. Yes, this is precisely the functionality the sensor event resolution circuitry offers. Please take a look at the Circuit and Switch . Q. The latest image tag does not point to latest release tag? A. When it comes to image tags, the golden rule is do not trust the latest tag. Always use the pinned version of the images. We will try to keep the latest in sync with the latest release version. Q. Where can I find the event structure for a particular event-source? A. Please refer this file to understand the structure of different types of events dispatched by event-source pod.","title":"FAQs"},{"location":"FAQ/#faqs","text":"Q. How to get started with Argo Events? A . Recommended way to get started with Argo Events is, Read the basic concepts about EventBus , Sensor and Event Source . Install the setup as outlined here . Read the tutorials available here . Q. Can I deploy event-source and sensor in a namespace different that argo-events ? A . Yes. If you want to deploy the event-source in a different namespace that argo-events , then please update the event-source definition with desired namespace and service account. Make sure to grant the service account the necessary roles. Q. How to debug Argo-Events. A . Make sure you have installed everything as instructed here . Make sure you have EventBus resource created in the namespace. The event-bus, event-source and sensor pods must be running. If you see any issue with the pods, check the logs for sensor-controller, event-source-controller or event-bus-controller. If event-source and sensor pods are running, but you are not receiving any events: Make sure you have configured the event source correctly. Check the logs of the event-source pod's containers. Note: You can set environment variable DEBUG_LOG:true in any of the containers to output debug logs. Q. Event-source pod is receiving the events but nothing happens. A . Check the sensor resource is deployed and a pod is running for the resource. If sensor pod is running, check for the logs that says Started to subscribe events for triggers . If the sensor has subscribed to the event-bus but unable to create the trigger resource, raise an issue on GitHub. Q. Helm chart installation does not work. A. The helm chart for argo events is maintained by the community and can be out of sync with latest release version. The official installation file is available here . If you notice the helm chart is outdated, we encourage you to contribute to the argo-helm . Q. Kustomization file doesn't have a X resource. A. The kustomization.yaml file is maintained by the community. If you notice that it is out of sync with the official installation file, please raise a PR. Q. Can I use Minio event-source for AWS S3 notifications? A. No. Minio event-source is exclusive for the Minio server. If you want to trigger workloads on AWS S3 bucket notification, then set up the AWS SNS event-source. Q. If I have multiple event dependencies and triggers in a single sensor, can I execute a specific trigger upon a specific event? A. Yes, this is precisely the functionality the sensor event resolution circuitry offers. Please take a look at the Circuit and Switch . Q. The latest image tag does not point to latest release tag? A. When it comes to image tags, the golden rule is do not trust the latest tag. Always use the pinned version of the images. We will try to keep the latest in sync with the latest release version. Q. Where can I find the event structure for a particular event-source? A. Please refer this file to understand the structure of different types of events dispatched by event-source pod.","title":"FAQs"},{"location":"developer_guide/","text":"Developer Guide Setup your DEV environment Argo Events is native to Kubernetes so you'll need a running Kubernetes cluster. This guide includes steps for Minikube for local development, but if you have another cluster you can ignore the Minikube specific step 3. Requirements Golang 1.13 Docker Installation Setup 1. Get the project git clone git@github.com:argoproj/argo-events cd argo-events 2. Start Minikube and point Docker Client to Minikube's Docker Daemon minikube start eval $(minikube docker-env) 3. Build the project make all Changing Types If you're making a change to the pkg/apis package, please ensure you re-run following command for code regeneration. $ make codegen","title":"Developer Guide"},{"location":"developer_guide/#developer-guide","text":"","title":"Developer Guide"},{"location":"developer_guide/#setup-your-dev-environment","text":"Argo Events is native to Kubernetes so you'll need a running Kubernetes cluster. This guide includes steps for Minikube for local development, but if you have another cluster you can ignore the Minikube specific step 3.","title":"Setup your DEV environment"},{"location":"developer_guide/#requirements","text":"Golang 1.13 Docker","title":"Requirements"},{"location":"developer_guide/#installation-setup","text":"","title":"Installation &amp; Setup"},{"location":"developer_guide/#1-get-the-project","text":"git clone git@github.com:argoproj/argo-events cd argo-events","title":"1. Get the project"},{"location":"developer_guide/#2-start-minikube-and-point-docker-client-to-minikubes-docker-daemon","text":"minikube start eval $(minikube docker-env)","title":"2. Start Minikube and point Docker Client to Minikube's Docker Daemon"},{"location":"developer_guide/#3-build-the-project","text":"make all","title":"3. Build the project"},{"location":"developer_guide/#changing-types","text":"If you're making a change to the pkg/apis package, please ensure you re-run following command for code regeneration. $ make codegen","title":"Changing Types"},{"location":"installation/","text":"Installation Requirements Kubernetes cluster =v1.11 Installed the kubectl command-line tool v1.11.0 Using kubectl Cluster-wide Installation Create the namespace kubectl create namespace argo-events Deploy Argo Events, SA, ClusterRoles, Sensor Controller, EventBus and EventSource Controller kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/manifests/install.yaml NOTE: * On GKE, you may need to grant your account the ability to create new custom resource definitions and clusterroles kubectl create clusterrolebinding YOURNAME-cluster-admin-binding --clusterrole=cluster-admin --user=YOUREMAIL@gmail.com * On Openshift, make sure to grant `anyuid` scc to the service account. Namespace Installation Create the namespace kubectl create namespace argo-events Deploy Argo Events, SA, Roles, Sensor Controller, EventBus and EventSource Controller kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/manifests/namespace-install.yaml NOTE: * On GKE, you may need to grant your account the ability to create new custom resource definitions kubectl create clusterrolebinding YOURNAME-cluster-admin-binding --clusterrole=cluster-admin --user=YOUREMAIL@gmail.com * On Openshift, make sure to grant `anyuid` scc to the service account. Step-by-Step Installation Create the namespace kubectl create namespace argo-events Create the service account kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/manifests/base/argo-events-sa.yaml Create the role kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/manifests/namespace-install/rbac/argo-events-role.yaml Create the rolebinding kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/manifests/namespace-install/rbac/argo-events-role-binding.yaml Install the sensor custom resource definition kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/manifests/base/crds/argopoj.io_sensors.yaml Install the eventbus custom resource definition kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/manifests/base/crds/argopoj.io_eventbus.yaml Install the event-source custom resource definition kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/manifests/base/crds/argopoj.io_eventsources.yaml Deploy the sensor controller kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/manifests/base/sensor-controller/sensor-controller-deployment.yaml Deploy the eventbus controller kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/manifests/base/eventbus-controller/eventbus-controller-deployment.yaml Deploy the event-source controller kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/manifests/base/eventsource-controller/eventsource-controller-deployment.yaml Deploy the eventbus. kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/eventbus/native.yaml Using Kustomize Use either cluster-install or namespace-install folder as your base for Kustomize. kustomization.yaml : bases: - github.com/argoproj/argo-events/manifests/cluster-install # OR - github.com/argoproj/argo-events/manifests/namespace-install Using Helm Chart Note: This method does not work with Helm 3, only Helm 2. Make sure you have helm client installed and Tiller server is running. To install helm, follow the link. Create namespace called argo-events. Add argoproj repository helm repo add argo https://argoproj.github.io/argo-helm The helm chart for argo-events is maintained solely by the community and hence the image version for controllers can go out of sync. Update the image version in values.yaml to v0.17.0. Install argo-events chart helm install argo-events argo/argo-events Migrate to v0.17.0 If you are looking to migrate Argo Events 0.16.0 to v0.17.0, please read the migration docs .","title":"Installation"},{"location":"installation/#installation","text":"","title":"Installation"},{"location":"installation/#requirements","text":"Kubernetes cluster =v1.11 Installed the kubectl command-line tool v1.11.0","title":"Requirements"},{"location":"installation/#using-kubectl","text":"","title":"Using kubectl"},{"location":"installation/#cluster-wide-installation","text":"Create the namespace kubectl create namespace argo-events Deploy Argo Events, SA, ClusterRoles, Sensor Controller, EventBus and EventSource Controller kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/manifests/install.yaml NOTE: * On GKE, you may need to grant your account the ability to create new custom resource definitions and clusterroles kubectl create clusterrolebinding YOURNAME-cluster-admin-binding --clusterrole=cluster-admin --user=YOUREMAIL@gmail.com * On Openshift, make sure to grant `anyuid` scc to the service account.","title":"Cluster-wide Installation"},{"location":"installation/#namespace-installation","text":"Create the namespace kubectl create namespace argo-events Deploy Argo Events, SA, Roles, Sensor Controller, EventBus and EventSource Controller kubectl apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/manifests/namespace-install.yaml NOTE: * On GKE, you may need to grant your account the ability to create new custom resource definitions kubectl create clusterrolebinding YOURNAME-cluster-admin-binding --clusterrole=cluster-admin --user=YOUREMAIL@gmail.com * On Openshift, make sure to grant `anyuid` scc to the service account.","title":"Namespace Installation"},{"location":"installation/#step-by-step-installation","text":"Create the namespace kubectl create namespace argo-events Create the service account kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/manifests/base/argo-events-sa.yaml Create the role kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/manifests/namespace-install/rbac/argo-events-role.yaml Create the rolebinding kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/manifests/namespace-install/rbac/argo-events-role-binding.yaml Install the sensor custom resource definition kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/manifests/base/crds/argopoj.io_sensors.yaml Install the eventbus custom resource definition kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/manifests/base/crds/argopoj.io_eventbus.yaml Install the event-source custom resource definition kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/manifests/base/crds/argopoj.io_eventsources.yaml Deploy the sensor controller kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/manifests/base/sensor-controller/sensor-controller-deployment.yaml Deploy the eventbus controller kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/manifests/base/eventbus-controller/eventbus-controller-deployment.yaml Deploy the event-source controller kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/manifests/base/eventsource-controller/eventsource-controller-deployment.yaml Deploy the eventbus. kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/eventbus/native.yaml","title":"Step-by-Step Installation"},{"location":"installation/#using-kustomize","text":"Use either cluster-install or namespace-install folder as your base for Kustomize. kustomization.yaml : bases: - github.com/argoproj/argo-events/manifests/cluster-install # OR - github.com/argoproj/argo-events/manifests/namespace-install","title":"Using Kustomize"},{"location":"installation/#using-helm-chart","text":"Note: This method does not work with Helm 3, only Helm 2. Make sure you have helm client installed and Tiller server is running. To install helm, follow the link. Create namespace called argo-events. Add argoproj repository helm repo add argo https://argoproj.github.io/argo-helm The helm chart for argo-events is maintained solely by the community and hence the image version for controllers can go out of sync. Update the image version in values.yaml to v0.17.0. Install argo-events chart helm install argo-events argo/argo-events","title":"Using Helm Chart"},{"location":"installation/#migrate-to-v0170","text":"If you are looking to migrate Argo Events 0.16.0 to v0.17.0, please read the migration docs .","title":"Migrate to v0.17.0"},{"location":"quick_start/","text":"Getting Started We are going to set up a sensor and event-source for webhook. The goal is to trigger an Argo workflow upon a HTTP Post request. Note: You will need to have Argo Workflows installed to make this work. Make sure to have the eventbus pods running in the namespace. Run following command to create the eventbus, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/eventbus/native.yaml Setup event-source for webhook as follows, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/webhook.yaml The above event-source contains a single event configuration that runs an HTTP server on port 12000 with endpoint example . After running the above command, the event-source controller will create a pod and service. Create webhook sensor, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/webhook.yaml Once the sensor object is created, sensor controller will create corresponding pod and a service. Expose the event-source pod via Ingress, OpenShift Route or port forward to consume requests over HTTP. kubectl -n argo-events port-forward event-source-pod-name 12000:12000 Use either Curl or Postman to send a post request to the http://localhost:12000/example curl -d { message : this is my first webhook } -H Content-Type: application/json -X POST http://localhost:12000/example Verify that an Argo workflow was triggered. kubectl -n argo-events get workflows | grep webhook","title":"Getting Started"},{"location":"quick_start/#getting-started","text":"We are going to set up a sensor and event-source for webhook. The goal is to trigger an Argo workflow upon a HTTP Post request. Note: You will need to have Argo Workflows installed to make this work. Make sure to have the eventbus pods running in the namespace. Run following command to create the eventbus, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/eventbus/native.yaml Setup event-source for webhook as follows, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/webhook.yaml The above event-source contains a single event configuration that runs an HTTP server on port 12000 with endpoint example . After running the above command, the event-source controller will create a pod and service. Create webhook sensor, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/webhook.yaml Once the sensor object is created, sensor controller will create corresponding pod and a service. Expose the event-source pod via Ingress, OpenShift Route or port forward to consume requests over HTTP. kubectl -n argo-events port-forward event-source-pod-name 12000:12000 Use either Curl or Postman to send a post request to the http://localhost:12000/example curl -d { message : this is my first webhook } -H Content-Type: application/json -X POST http://localhost:12000/example Verify that an Argo workflow was triggered. kubectl -n argo-events get workflows | grep webhook","title":"Getting Started"},{"location":"concepts/architecture/","text":"Architecture Main components of Argo Events are: Event Source Sensor Eventbus Trigger","title":"Architecture"},{"location":"concepts/architecture/#architecture","text":"Main components of Argo Events are: Event Source Sensor Eventbus Trigger","title":"Architecture"},{"location":"concepts/event_source/","text":"Event Source An EventSource defines the configurations required to consume events from external sources like AWS SNS, SQS, GCP PubSub, Webhooks, etc. It further transforms the events into the cloudevents and dispatches them over to the eventbus. Available event-sources: AMQP AWS SNS AWS SQS Cron Schedules GCP PubSub GitHub GitLab HDFS File Based Events Kafka Minio NATS MQTT K8s Resources Slack NetApp StorageGrid Webhooks Stripe NSQ Emitter Redis Azure Events Hub Specification The complete specification is available here . Examples Examples are located under examples/event-sources .","title":"Event Source"},{"location":"concepts/event_source/#event-source","text":"An EventSource defines the configurations required to consume events from external sources like AWS SNS, SQS, GCP PubSub, Webhooks, etc. It further transforms the events into the cloudevents and dispatches them over to the eventbus. Available event-sources: AMQP AWS SNS AWS SQS Cron Schedules GCP PubSub GitHub GitLab HDFS File Based Events Kafka Minio NATS MQTT K8s Resources Slack NetApp StorageGrid Webhooks Stripe NSQ Emitter Redis Azure Events Hub","title":"Event Source"},{"location":"concepts/event_source/#specification","text":"The complete specification is available here .","title":"Specification"},{"location":"concepts/event_source/#examples","text":"Examples are located under examples/event-sources .","title":"Examples"},{"location":"concepts/eventbus/","text":"Eventbus The eventbus acts as the transport layer of Argo-Events by connecting the event-sources and sensors. Event-Sources publish the events while the sensors subscribe to the events to execute triggers. The current implementation of the eventbus is powered by NATS streaming.","title":"Eventbus"},{"location":"concepts/eventbus/#eventbus","text":"The eventbus acts as the transport layer of Argo-Events by connecting the event-sources and sensors. Event-Sources publish the events while the sensors subscribe to the events to execute triggers. The current implementation of the eventbus is powered by NATS streaming.","title":"Eventbus"},{"location":"concepts/sensor/","text":"Sensor Sensor defines a set of event dependencies (inputs) and triggers (outputs). It listens to events on the eventbus and acts as an event dependency manager to resolve and execute the triggers. Event dependency A dependency is an event the sensor is waiting to happen. Specification Complete specification is available here . Examples Examples are located under examples/sensors .","title":"Sensor"},{"location":"concepts/sensor/#sensor","text":"Sensor defines a set of event dependencies (inputs) and triggers (outputs). It listens to events on the eventbus and acts as an event dependency manager to resolve and execute the triggers.","title":"Sensor"},{"location":"concepts/sensor/#event-dependency","text":"A dependency is an event the sensor is waiting to happen.","title":"Event dependency"},{"location":"concepts/sensor/#specification","text":"Complete specification is available here .","title":"Specification"},{"location":"concepts/sensor/#examples","text":"Examples are located under examples/sensors .","title":"Examples"},{"location":"concepts/trigger/","text":"Trigger A Trigger is the resource/workload executed by the sensor once the event dependencies are resolved. Trigger Types Argo Workflows Standard K8s Objects HTTP Requests AWS Lambda NATS Messages Kafka Messages Slack Notifications Argo Rollouts CR Custom / Build Your Own Triggers Apache OpenWhisk","title":"Trigger"},{"location":"concepts/trigger/#trigger","text":"A Trigger is the resource/workload executed by the sensor once the event dependencies are resolved.","title":"Trigger"},{"location":"concepts/trigger/#trigger-types","text":"Argo Workflows Standard K8s Objects HTTP Requests AWS Lambda NATS Messages Kafka Messages Slack Notifications Argo Rollouts CR Custom / Build Your Own Triggers Apache OpenWhisk","title":"Trigger Types"},{"location":"setup/amqp/","text":"AMQP AMQP event-source listens to messages on the MQ and helps sensor trigger the workloads. Event Structure The structure of an event dispatched by the event-source over the eventbus looks like following, { context : { type : type_of_event_source , specversion : cloud_events_version , source : name_of_the_event_source , id : unique_event_id , time : event_time , datacontenttype : type_of_data , subject : name_of_the_configuration_within_event_source }, data : { contentType : ContentType is the MIME content type , contentEncoding : ContentEncoding is the MIME content encoding , deliveryMode : Delivery mode can be either - non-persistent (1) or persistent (2) , priority : Priority refers to the use - 0 to 9 , correlationId : CorrelationId is the correlation identifier , replyTo : ReplyTo is the address to reply to (ex: RPC) , expiration : Expiration refers to message expiration spec , messageId : MessageId is message identifier , timestamp : Timestamp refers to the message timestamp , type : Type refers to the message type name , appId : AppId refers to the application id , exchange : Exchange is basic.publish exchange , routingKey : RoutingKey is basic.publish routing key , body : Body represents the messsage body , } } Setup Lets set up RabbitMQ locally, apiVersion : v1 kind : Service metadata : labels : component : rabbitmq name : rabbitmq - service spec : ports : - port : 5672 selector : app : taskQueue component : rabbitmq --- apiVersion : v1 kind : ReplicationController metadata : labels : component : rabbitmq name : rabbitmq - controller spec : replicas : 1 template : metadata : labels : app : taskQueue component : rabbitmq spec : containers : - image : rabbitmq name : rabbitmq ports : - containerPort : 5672 resources : limits : cpu : 100 m Make sure the RabbitMQ controller pod is up and running before proceeding further. Expose the RabbitMQ server to local publisher using port-forward , kubectl -n argo-events port-forward rabbitmq-pod-name 5672:5672 Create the event source by running the following command. kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/amqp.yaml Inspect the event-source pod logs to make sure it was able to subscribe to the exchange specified in the event source to consume messages. Create the sensor by running the following command, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/amqp.yaml Lets set up a rabbitmq publisher. If you don't have pika installed, run, python -m pip install pika --upgrade Open a python REPL and run following code to publish a message on exhange called test . import pika connection = pika . BlockingConnection ( pika . ConnectionParameters ( localhost )) channel = connection . channel () channel . basic_publish ( exchange = test , routing_key = hello , body = { message : hello } ) As soon as you publish a message, sensor will trigger an Argo workflow. Run argo list to find the workflow. Troubleshoot Please read the FAQ .","title":"AMQP"},{"location":"setup/amqp/#amqp","text":"AMQP event-source listens to messages on the MQ and helps sensor trigger the workloads.","title":"AMQP"},{"location":"setup/amqp/#event-structure","text":"The structure of an event dispatched by the event-source over the eventbus looks like following, { context : { type : type_of_event_source , specversion : cloud_events_version , source : name_of_the_event_source , id : unique_event_id , time : event_time , datacontenttype : type_of_data , subject : name_of_the_configuration_within_event_source }, data : { contentType : ContentType is the MIME content type , contentEncoding : ContentEncoding is the MIME content encoding , deliveryMode : Delivery mode can be either - non-persistent (1) or persistent (2) , priority : Priority refers to the use - 0 to 9 , correlationId : CorrelationId is the correlation identifier , replyTo : ReplyTo is the address to reply to (ex: RPC) , expiration : Expiration refers to message expiration spec , messageId : MessageId is message identifier , timestamp : Timestamp refers to the message timestamp , type : Type refers to the message type name , appId : AppId refers to the application id , exchange : Exchange is basic.publish exchange , routingKey : RoutingKey is basic.publish routing key , body : Body represents the messsage body , } }","title":"Event Structure"},{"location":"setup/amqp/#setup","text":"Lets set up RabbitMQ locally, apiVersion : v1 kind : Service metadata : labels : component : rabbitmq name : rabbitmq - service spec : ports : - port : 5672 selector : app : taskQueue component : rabbitmq --- apiVersion : v1 kind : ReplicationController metadata : labels : component : rabbitmq name : rabbitmq - controller spec : replicas : 1 template : metadata : labels : app : taskQueue component : rabbitmq spec : containers : - image : rabbitmq name : rabbitmq ports : - containerPort : 5672 resources : limits : cpu : 100 m Make sure the RabbitMQ controller pod is up and running before proceeding further. Expose the RabbitMQ server to local publisher using port-forward , kubectl -n argo-events port-forward rabbitmq-pod-name 5672:5672 Create the event source by running the following command. kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/amqp.yaml Inspect the event-source pod logs to make sure it was able to subscribe to the exchange specified in the event source to consume messages. Create the sensor by running the following command, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/amqp.yaml Lets set up a rabbitmq publisher. If you don't have pika installed, run, python -m pip install pika --upgrade Open a python REPL and run following code to publish a message on exhange called test . import pika connection = pika . BlockingConnection ( pika . ConnectionParameters ( localhost )) channel = connection . channel () channel . basic_publish ( exchange = test , routing_key = hello , body = { message : hello } ) As soon as you publish a message, sensor will trigger an Argo workflow. Run argo list to find the workflow.","title":"Setup"},{"location":"setup/amqp/#troubleshoot","text":"Please read the FAQ .","title":"Troubleshoot"},{"location":"setup/aws-sns/","text":"AWS SNS SNS event-source subscribes to AWS SNS topics, listens events and helps sensor trigger the workloads. Event Structure The structure of an event dispatched by the event-source over eventbus looks like following, { context : { type : type_of_event_source , specversion : cloud_events_version , source : name_of_the_event_source , id : unique_event_id , time : event_time , datacontenttype : type_of_data , subject : name_of_the_configuration_within_event_source }, data : { header : sns headers , body : body refers to the sns notification data , } } Setup Create a topic called test using aws cli or AWS SNS console. Fetch your access and secret key for AWS account and base64 encode them. Create a secret called aws-secret as follows, apiVersion : v1 kind : Secret metadata : name : aws - secret type : Opaque data : accesskey : base64 - access - key secretkey : base64 - secret - key Deploy the secret kubectl -n argo-events apply -f aws-secret.yaml The event-source for AWS SNS creates a pod and exposes it via service. The name for the service is in event-source-name -eventsource-svc format. You will need to create an Ingress or Openshift Route for the event-source service so that it can be reached from AWS. You can find more information on Ingress or Route online. Create the event source by running the following command. Make sure to update the URL in the configuration within the event-source. kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/aws-sns.yaml Go to SNS settings on AWS and verify the webhook is registered. You can also check it by inspecting the event-source pod logs. Create the sensor by running the following command, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/aws-sns.yaml Publish a message to the SNS topic, and it will trigger an argo workflow. Run argo list to find the workflow. Troubleshoot Please read the FAQ .","title":"AWS SNS"},{"location":"setup/aws-sns/#aws-sns","text":"SNS event-source subscribes to AWS SNS topics, listens events and helps sensor trigger the workloads.","title":"AWS SNS"},{"location":"setup/aws-sns/#event-structure","text":"The structure of an event dispatched by the event-source over eventbus looks like following, { context : { type : type_of_event_source , specversion : cloud_events_version , source : name_of_the_event_source , id : unique_event_id , time : event_time , datacontenttype : type_of_data , subject : name_of_the_configuration_within_event_source }, data : { header : sns headers , body : body refers to the sns notification data , } }","title":"Event Structure"},{"location":"setup/aws-sns/#setup","text":"Create a topic called test using aws cli or AWS SNS console. Fetch your access and secret key for AWS account and base64 encode them. Create a secret called aws-secret as follows, apiVersion : v1 kind : Secret metadata : name : aws - secret type : Opaque data : accesskey : base64 - access - key secretkey : base64 - secret - key Deploy the secret kubectl -n argo-events apply -f aws-secret.yaml The event-source for AWS SNS creates a pod and exposes it via service. The name for the service is in event-source-name -eventsource-svc format. You will need to create an Ingress or Openshift Route for the event-source service so that it can be reached from AWS. You can find more information on Ingress or Route online. Create the event source by running the following command. Make sure to update the URL in the configuration within the event-source. kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/aws-sns.yaml Go to SNS settings on AWS and verify the webhook is registered. You can also check it by inspecting the event-source pod logs. Create the sensor by running the following command, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/aws-sns.yaml Publish a message to the SNS topic, and it will trigger an argo workflow. Run argo list to find the workflow.","title":"Setup"},{"location":"setup/aws-sns/#troubleshoot","text":"Please read the FAQ .","title":"Troubleshoot"},{"location":"setup/aws-sqs/","text":"AWS SQS SQS event-source listens to messages on AWS SQS queue and helps sensor trigger workloads. Event Structure The structure of an event dispatched by the event-source over the eventbus looks like following, { context : { type : type_of_event_source , specversion : cloud_events_version , source : name_of_the_event_source , id : unique_event_id , time : event_time , datacontenttype : type_of_data , subject : name_of_the_configuration_within_event_source }, data : { messageId : message id , // Each message attribute consists of a Name, Type, and Value. For more information, // see Amazon SQS Message Attributes // (https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-message-attributes.html) // in the Amazon Simple Queue Service Developer Guide. messageAttributes : message attributes , body : Body is the message data , } } Setup Create a queue called test either using aws cli or AWS SQS management console. Fetch your access and secret key for AWS account and base64 encode them. Create a secret called aws-secret as follows, apiVersion : v1 kind : Secret metadata : name : aws - secret type : Opaque data : accesskey : base64 - access - key secretkey : base64 - secret - key Deploy the secret kubectl -n argo-events apply -f aws-secret.yaml Create the event source by running the following command. kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/aws-sqs.yaml Inspect the event-source pod logs to make sure it was able to subscribe to the queue specified in the event source to consume messages. Create the sensor by running the following command, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/aws-sqs.yaml Dispatch a message on sqs queue, aws sqs send-message --queue-url https://sqs.us-east-1.amazonaws.com/XXXXX/test --message-body { message : hello } Once a message is published, an argo workflow will be triggered. Run argo list to find the workflow. Troubleshoot Please read the FAQ .","title":"AWS SQS"},{"location":"setup/aws-sqs/#aws-sqs","text":"SQS event-source listens to messages on AWS SQS queue and helps sensor trigger workloads.","title":"AWS SQS"},{"location":"setup/aws-sqs/#event-structure","text":"The structure of an event dispatched by the event-source over the eventbus looks like following, { context : { type : type_of_event_source , specversion : cloud_events_version , source : name_of_the_event_source , id : unique_event_id , time : event_time , datacontenttype : type_of_data , subject : name_of_the_configuration_within_event_source }, data : { messageId : message id , // Each message attribute consists of a Name, Type, and Value. For more information, // see Amazon SQS Message Attributes // (https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-message-attributes.html) // in the Amazon Simple Queue Service Developer Guide. messageAttributes : message attributes , body : Body is the message data , } }","title":"Event Structure"},{"location":"setup/aws-sqs/#setup","text":"Create a queue called test either using aws cli or AWS SQS management console. Fetch your access and secret key for AWS account and base64 encode them. Create a secret called aws-secret as follows, apiVersion : v1 kind : Secret metadata : name : aws - secret type : Opaque data : accesskey : base64 - access - key secretkey : base64 - secret - key Deploy the secret kubectl -n argo-events apply -f aws-secret.yaml Create the event source by running the following command. kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/aws-sqs.yaml Inspect the event-source pod logs to make sure it was able to subscribe to the queue specified in the event source to consume messages. Create the sensor by running the following command, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/aws-sqs.yaml Dispatch a message on sqs queue, aws sqs send-message --queue-url https://sqs.us-east-1.amazonaws.com/XXXXX/test --message-body { message : hello } Once a message is published, an argo workflow will be triggered. Run argo list to find the workflow.","title":"Setup"},{"location":"setup/aws-sqs/#troubleshoot","text":"Please read the FAQ .","title":"Troubleshoot"},{"location":"setup/calendar/","text":"Calendar Calendar event-source generates events on either a cron schedule or an interval and helps sensor trigger workloads. Event Structure The structure of an event dispatched by the event-source over the eventbus looks like following, { context : { type : type_of_event_source , specversion : cloud_events_version , source : name_of_the_event_source , id : unique_event_id , time : event_time , datacontenttype : type_of_data , subject : name_of_the_configuration_within_event_source }, data : { eventTime : {/* UTC time of the event */}, userPayload : { /* static payload available in the event source */}, } } Specification Calendar event-source specification is available here . Setup Install the event source in the argo-events namespace, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/calendar.yaml The event-source will generate events at every 10 seconds. Let's create the sensor, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/calendar.yaml Once the sensor pod is in running state, wait for next interval to occur for sensor to trigger workflow. Troubleshoot Please read the FAQ .","title":"Calendar"},{"location":"setup/calendar/#calendar","text":"Calendar event-source generates events on either a cron schedule or an interval and helps sensor trigger workloads.","title":"Calendar"},{"location":"setup/calendar/#event-structure","text":"The structure of an event dispatched by the event-source over the eventbus looks like following, { context : { type : type_of_event_source , specversion : cloud_events_version , source : name_of_the_event_source , id : unique_event_id , time : event_time , datacontenttype : type_of_data , subject : name_of_the_configuration_within_event_source }, data : { eventTime : {/* UTC time of the event */}, userPayload : { /* static payload available in the event source */}, } }","title":"Event Structure"},{"location":"setup/calendar/#specification","text":"Calendar event-source specification is available here .","title":"Specification"},{"location":"setup/calendar/#setup","text":"Install the event source in the argo-events namespace, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/calendar.yaml The event-source will generate events at every 10 seconds. Let's create the sensor, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/calendar.yaml Once the sensor pod is in running state, wait for next interval to occur for sensor to trigger workflow.","title":"Setup"},{"location":"setup/calendar/#troubleshoot","text":"Please read the FAQ .","title":"Troubleshoot"},{"location":"setup/emitter/","text":"Emitter Emitter event-source subscribes to a channel and helps sensor trigger the workloads. Event Structure The structure of an event dispatched by the event-source over the eventbus looks like following, { context : { type : type_of_event_source , specversion : cloud_events_version , source : name_of_the_event_source , id : unique_event_id , time : event_time , datacontenttype : type_of_data , subject : name_of_the_configuration_within_event_source }, data : { topic : name_of_the_topic , body : message_payload } } Specification Emitter event-source specification is available here . Setup Deploy the emitter in your local K8s cluster, --- apiVersion: v1 kind: Service metadata: name: broker labels: app: broker spec: clusterIP: None ports: - port: 4000 targetPort: 4000 selector: app: broker --- apiVersion: apps/v1 kind: Deployment metadata: name: broker spec: replicas: 1 selector: matchLabels: app: broker template: metadata: labels: app: broker spec: containers: - env: - name: EMITTER_LICENSE value: zT83oDV0DWY5_JysbSTPTDr8KB0AAAAAAAAAAAAAAAI # This is a test license, DO NOT USE IN PRODUCTION! - name: EMITTER_CLUSTER_SEED value: broker - name: EMITTER_CLUSTER_ADVERTISE value: private:4000 name: broker image: emitter/server:latest ports: - containerPort: 8080 - containerPort: 443 - containerPort: 4000 volumeMounts: - name: broker-volume mountPath: /data volumes: - name: broker-volume hostPath: path: /emitter #directory on host Create the event-source by running the following command. kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/emitter.yaml Inspect the event-source pod logs to make sure it was able to subscribe to the topic specified in the event source to consume messages. Create the sensor by running the following command, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/emitter.yaml Send a message on emitter channel using one of the clients https://emitter.io/develop/golang/ Once a message is published, an argo workflow will be triggered. Run argo list to find the workflow. Troubleshoot Please read the FAQ .","title":"Emitter"},{"location":"setup/emitter/#emitter","text":"Emitter event-source subscribes to a channel and helps sensor trigger the workloads.","title":"Emitter"},{"location":"setup/emitter/#event-structure","text":"The structure of an event dispatched by the event-source over the eventbus looks like following, { context : { type : type_of_event_source , specversion : cloud_events_version , source : name_of_the_event_source , id : unique_event_id , time : event_time , datacontenttype : type_of_data , subject : name_of_the_configuration_within_event_source }, data : { topic : name_of_the_topic , body : message_payload } }","title":"Event Structure"},{"location":"setup/emitter/#specification","text":"Emitter event-source specification is available here .","title":"Specification"},{"location":"setup/emitter/#setup","text":"Deploy the emitter in your local K8s cluster, --- apiVersion: v1 kind: Service metadata: name: broker labels: app: broker spec: clusterIP: None ports: - port: 4000 targetPort: 4000 selector: app: broker --- apiVersion: apps/v1 kind: Deployment metadata: name: broker spec: replicas: 1 selector: matchLabels: app: broker template: metadata: labels: app: broker spec: containers: - env: - name: EMITTER_LICENSE value: zT83oDV0DWY5_JysbSTPTDr8KB0AAAAAAAAAAAAAAAI # This is a test license, DO NOT USE IN PRODUCTION! - name: EMITTER_CLUSTER_SEED value: broker - name: EMITTER_CLUSTER_ADVERTISE value: private:4000 name: broker image: emitter/server:latest ports: - containerPort: 8080 - containerPort: 443 - containerPort: 4000 volumeMounts: - name: broker-volume mountPath: /data volumes: - name: broker-volume hostPath: path: /emitter #directory on host Create the event-source by running the following command. kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/emitter.yaml Inspect the event-source pod logs to make sure it was able to subscribe to the topic specified in the event source to consume messages. Create the sensor by running the following command, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/emitter.yaml Send a message on emitter channel using one of the clients https://emitter.io/develop/golang/ Once a message is published, an argo workflow will be triggered. Run argo list to find the workflow.","title":"Setup"},{"location":"setup/emitter/#troubleshoot","text":"Please read the FAQ .","title":"Troubleshoot"},{"location":"setup/file/","text":"File File event-source listens to file system events and helps sensor trigger workloads. Event Structure The structure of an event dispatched by the event-source over the eventbus looks like following, { context : { type : type_of_event_source , specversion : cloud_events_version , source : name_of_the_event_source , id : unique_event_id , time : event_time , datacontenttype : type_of_data , subject : name_of_the_configuration_within_event_source }, data : { name : Relative path to the file or directory , op : File operation that triggered the event // Create, Write, Remove, Rename, Chmod } } Specification File event-source specification is available here . Setup Create the event source by running the following command. kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/file.yaml The event source has configuration to listen to file system events for test-data directory and file called x.txt . Create the sensor by running the following command, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/file.yaml Log into the event-source pod by running following command, kubectl -n argo-events exec -it event-source-pod-name -c file-events -- /bin/bash Let's create a file called x.txt under test-data directory in the event-source pod. cd test-data cat EOF x.txt hello EOF Once you create file x.txt , the sensor will trigger argo workflow. Run argo list to find the workflow. For real-world use cases, you should use PersistentVolumeClaim. Troubleshoot Please read the FAQ .","title":"File"},{"location":"setup/file/#file","text":"File event-source listens to file system events and helps sensor trigger workloads.","title":"File"},{"location":"setup/file/#event-structure","text":"The structure of an event dispatched by the event-source over the eventbus looks like following, { context : { type : type_of_event_source , specversion : cloud_events_version , source : name_of_the_event_source , id : unique_event_id , time : event_time , datacontenttype : type_of_data , subject : name_of_the_configuration_within_event_source }, data : { name : Relative path to the file or directory , op : File operation that triggered the event // Create, Write, Remove, Rename, Chmod } }","title":"Event Structure"},{"location":"setup/file/#specification","text":"File event-source specification is available here .","title":"Specification"},{"location":"setup/file/#setup","text":"Create the event source by running the following command. kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/file.yaml The event source has configuration to listen to file system events for test-data directory and file called x.txt . Create the sensor by running the following command, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/file.yaml Log into the event-source pod by running following command, kubectl -n argo-events exec -it event-source-pod-name -c file-events -- /bin/bash Let's create a file called x.txt under test-data directory in the event-source pod. cd test-data cat EOF x.txt hello EOF Once you create file x.txt , the sensor will trigger argo workflow. Run argo list to find the workflow. For real-world use cases, you should use PersistentVolumeClaim.","title":"Setup"},{"location":"setup/file/#troubleshoot","text":"Please read the FAQ .","title":"Troubleshoot"},{"location":"setup/gcp-pub-sub/","text":"GCP PubSub GCP PubSub event-source subscribes to messages published by GCP publisher and helps sensor trigger workloads. Event Structure The structure of an event dispatched by the event-source over the eventbus looks like following, { context : { type : type_of_event_source , specversion : cloud_events_version , source : name_of_the_event_source , id : unique_event_id , time : event_time , datacontenttype : type_of_data , subject : name_of_the_configuration_within_event_source }, data : { id : message id , // Attributes represents the key-value pairs the current message // is labelled with. attributes : key-values , publishTime : // The time at which the message was published , body : body refers to the message data , } } Specification GCP PubSub event-source specification is available here . Setup Fetch the project credentials JSON file from GCP console. Create a K8s secret called gcp-credentials to store the credentials file apiVersion : v1 data : key . json : YOUR_CREDENTIALS_STRING_FROM_JSON_FILE kind : Secret metadata : name : gcp - credentials namespace : argo - events type : Opaque Create the event source by running the following command. kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/gcp-pubsub.yaml Inspect the event-source pod logs to make sure it was able to subscribe to the topic. Create the sensor by running the following command, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/gcp-pubsub.yaml Publish a message from GCP PubSub console. Once a message is published, an argo workflow will be triggered. Run argo list to find the workflow. Troubleshoot Please read the FAQ .","title":"GCP PubSub"},{"location":"setup/gcp-pub-sub/#gcp-pubsub","text":"GCP PubSub event-source subscribes to messages published by GCP publisher and helps sensor trigger workloads.","title":"GCP PubSub"},{"location":"setup/gcp-pub-sub/#event-structure","text":"The structure of an event dispatched by the event-source over the eventbus looks like following, { context : { type : type_of_event_source , specversion : cloud_events_version , source : name_of_the_event_source , id : unique_event_id , time : event_time , datacontenttype : type_of_data , subject : name_of_the_configuration_within_event_source }, data : { id : message id , // Attributes represents the key-value pairs the current message // is labelled with. attributes : key-values , publishTime : // The time at which the message was published , body : body refers to the message data , } }","title":"Event Structure"},{"location":"setup/gcp-pub-sub/#specification","text":"GCP PubSub event-source specification is available here .","title":"Specification"},{"location":"setup/gcp-pub-sub/#setup","text":"Fetch the project credentials JSON file from GCP console. Create a K8s secret called gcp-credentials to store the credentials file apiVersion : v1 data : key . json : YOUR_CREDENTIALS_STRING_FROM_JSON_FILE kind : Secret metadata : name : gcp - credentials namespace : argo - events type : Opaque Create the event source by running the following command. kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/gcp-pubsub.yaml Inspect the event-source pod logs to make sure it was able to subscribe to the topic. Create the sensor by running the following command, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/gcp-pubsub.yaml Publish a message from GCP PubSub console. Once a message is published, an argo workflow will be triggered. Run argo list to find the workflow.","title":"Setup"},{"location":"setup/gcp-pub-sub/#troubleshoot","text":"Please read the FAQ .","title":"Troubleshoot"},{"location":"setup/github/","text":"GitHub GitHub event-source programmatically configures webhooks for projects on GitHub and helps sensor trigger the workloads on events. Event Structure The structure of an event dispatched by the event-source over the eventbus looks like following, { context : { type : type_of_event_source , specversion : cloud_events_version , source : name_of_the_event_source , id : unique_event_id , time : event_time , datacontenttype : type_of_data , subject : name_of_the_configuration_within_event_source }, data : { body : Body is the github event data , headers : Headers from the Gitlab event , } } Specification GitHub event-source specification is available here . Setup Create an API token if you don't have one. Follow instructions to create a new GitHub API Token. Grant it the repo_hook permissions. Base64 encode your api token key, echo -n api-token-key | base64 Create a secret called github-access . apiVersion : v1 kind : Secret metadata : name : github - access type : Opaque data : token : base64 - encoded - api - token - from - previous - step Deploy the secret into K8s cluster kubectl -n argo-events apply -f github-access.yaml The event-source for GitHub creates a pod and exposes it via service. The name for the service is in event-source-name -eventsource-svc format. You will need to create an Ingress or Openshift Route for the event-source service so that it can be reached from GitHub. You can find more information on Ingress or Route online. Create the event source by running the following command. Make sure to replace the url field. kubectl apply -n argo-events -f event-source-file-updated-in-previous-step Go to Webhooks under your project settings on GitHub and verify the webhook is registered. You can also do the same by looking at the event-source pod logs. Create the sensor by running the following command, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/github.yaml Make a change to one of your project files and commit. It will trigger an argo workflow. Run argo list to find the workflow. Troubleshoot Please read the FAQ .","title":"GitHub"},{"location":"setup/github/#github","text":"GitHub event-source programmatically configures webhooks for projects on GitHub and helps sensor trigger the workloads on events.","title":"GitHub"},{"location":"setup/github/#event-structure","text":"The structure of an event dispatched by the event-source over the eventbus looks like following, { context : { type : type_of_event_source , specversion : cloud_events_version , source : name_of_the_event_source , id : unique_event_id , time : event_time , datacontenttype : type_of_data , subject : name_of_the_configuration_within_event_source }, data : { body : Body is the github event data , headers : Headers from the Gitlab event , } }","title":"Event Structure"},{"location":"setup/github/#specification","text":"GitHub event-source specification is available here .","title":"Specification"},{"location":"setup/github/#setup","text":"Create an API token if you don't have one. Follow instructions to create a new GitHub API Token. Grant it the repo_hook permissions. Base64 encode your api token key, echo -n api-token-key | base64 Create a secret called github-access . apiVersion : v1 kind : Secret metadata : name : github - access type : Opaque data : token : base64 - encoded - api - token - from - previous - step Deploy the secret into K8s cluster kubectl -n argo-events apply -f github-access.yaml The event-source for GitHub creates a pod and exposes it via service. The name for the service is in event-source-name -eventsource-svc format. You will need to create an Ingress or Openshift Route for the event-source service so that it can be reached from GitHub. You can find more information on Ingress or Route online. Create the event source by running the following command. Make sure to replace the url field. kubectl apply -n argo-events -f event-source-file-updated-in-previous-step Go to Webhooks under your project settings on GitHub and verify the webhook is registered. You can also do the same by looking at the event-source pod logs. Create the sensor by running the following command, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/github.yaml Make a change to one of your project files and commit. It will trigger an argo workflow. Run argo list to find the workflow.","title":"Setup"},{"location":"setup/github/#troubleshoot","text":"Please read the FAQ .","title":"Troubleshoot"},{"location":"setup/gitlab/","text":"GitLab GitLab event-source programmatically configures webhooks for projects on GitLab and helps sensor trigger the workloads upon events. Event Structure The structure of an event dispatched by the event-source over the eventbus looks like following, { context : { type : type_of_event_source , specversion : cloud_events_version , source : name_of_the_event_source , id : unique_event_id , time : event_time , datacontenttype : type_of_data , subject : name_of_the_configuration_within_event_source }, data : { body : Body is the gitlab event data , headers : Headers from the Gitlab event , } } Specification GitLab event-source specification is available here . Setup Create an API token if you don't have one. Follow instructions to create a new GitLab API Token. Grant it the api permissions. Base64 encode your api token key, echo -n api-token-key | base64 Create a secret called gitlab-access . apiVersion : v1 kind : Secret metadata : name : gitlab - access type : Opaque data : token : base64 - encoded - api - token - from - previous - step Deploy the secret into K8s cluster. kubectl -n argo-events apply -f gitlab-access.yaml The event-source for GitLab creates a pod and exposes it via service. The name for the service is in event-source-name -eventsource-svc format. You will need to create an Ingress or Openshift Route for the event-source service so that it can be reached from GitLab. You can find more information on Ingress or Route online. Create the event source by running the following command. Make sure to update url field. kubectl apply -n argo-events -f event-source-file-updated-in-previous-step Go to Webhooks under your project settings on GitLab and verify the webhook is registered. Create the sensor by running the following command, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/gitlab.yaml Make a change to one of your project files and commit. It will trigger an argo workflow. Run argo list to find the workflow. Troubleshoot Please read the FAQ .","title":"GitLab"},{"location":"setup/gitlab/#gitlab","text":"GitLab event-source programmatically configures webhooks for projects on GitLab and helps sensor trigger the workloads upon events.","title":"GitLab"},{"location":"setup/gitlab/#event-structure","text":"The structure of an event dispatched by the event-source over the eventbus looks like following, { context : { type : type_of_event_source , specversion : cloud_events_version , source : name_of_the_event_source , id : unique_event_id , time : event_time , datacontenttype : type_of_data , subject : name_of_the_configuration_within_event_source }, data : { body : Body is the gitlab event data , headers : Headers from the Gitlab event , } }","title":"Event Structure"},{"location":"setup/gitlab/#specification","text":"GitLab event-source specification is available here .","title":"Specification"},{"location":"setup/gitlab/#setup","text":"Create an API token if you don't have one. Follow instructions to create a new GitLab API Token. Grant it the api permissions. Base64 encode your api token key, echo -n api-token-key | base64 Create a secret called gitlab-access . apiVersion : v1 kind : Secret metadata : name : gitlab - access type : Opaque data : token : base64 - encoded - api - token - from - previous - step Deploy the secret into K8s cluster. kubectl -n argo-events apply -f gitlab-access.yaml The event-source for GitLab creates a pod and exposes it via service. The name for the service is in event-source-name -eventsource-svc format. You will need to create an Ingress or Openshift Route for the event-source service so that it can be reached from GitLab. You can find more information on Ingress or Route online. Create the event source by running the following command. Make sure to update url field. kubectl apply -n argo-events -f event-source-file-updated-in-previous-step Go to Webhooks under your project settings on GitLab and verify the webhook is registered. Create the sensor by running the following command, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/gitlab.yaml Make a change to one of your project files and commit. It will trigger an argo workflow. Run argo list to find the workflow.","title":"Setup"},{"location":"setup/gitlab/#troubleshoot","text":"Please read the FAQ .","title":"Troubleshoot"},{"location":"setup/kafka/","text":"Kafka Kafka event-source listens to messages on topics and helps the sensor trigger workloads. Event Structure The structure of an event dispatched by the event-source over the eventbus looks like following, { context : { type : type_of_event_source , specversion : cloud_events_version , source : name_of_the_event_source , id : unique_event_id , time : event_time , datacontenttype : type_of_data , subject : name_of_the_configuration_within_event_source }, data : { topic : kafka_topic , partition : partition_number , body : message_body , timestamp : timestamp_of_the_message } } Specification Kafka event-source specification is available here . Setup Make sure to set up the Kafka cluster in Kubernetes if you don't already have one. You can refer to https://github.com/Yolean/kubernetes-kafka for installation instructions. Create the event source by running the following command. Make sure to update the appropriate fields. kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/kafka.yaml Create the sensor by running the following command, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/kafka.yaml Send message by using Kafka client. More info on how to send message at https://kafka.apache.org/quickstart Once a message is published, an argo workflow will be triggered. Run argo list to find the workflow. Troubleshoot Please read the FAQ .","title":"Kafka"},{"location":"setup/kafka/#kafka","text":"Kafka event-source listens to messages on topics and helps the sensor trigger workloads.","title":"Kafka"},{"location":"setup/kafka/#event-structure","text":"The structure of an event dispatched by the event-source over the eventbus looks like following, { context : { type : type_of_event_source , specversion : cloud_events_version , source : name_of_the_event_source , id : unique_event_id , time : event_time , datacontenttype : type_of_data , subject : name_of_the_configuration_within_event_source }, data : { topic : kafka_topic , partition : partition_number , body : message_body , timestamp : timestamp_of_the_message } }","title":"Event Structure"},{"location":"setup/kafka/#specification","text":"Kafka event-source specification is available here .","title":"Specification"},{"location":"setup/kafka/#setup","text":"Make sure to set up the Kafka cluster in Kubernetes if you don't already have one. You can refer to https://github.com/Yolean/kubernetes-kafka for installation instructions. Create the event source by running the following command. Make sure to update the appropriate fields. kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/kafka.yaml Create the sensor by running the following command, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/kafka.yaml Send message by using Kafka client. More info on how to send message at https://kafka.apache.org/quickstart Once a message is published, an argo workflow will be triggered. Run argo list to find the workflow.","title":"Setup"},{"location":"setup/kafka/#troubleshoot","text":"Please read the FAQ .","title":"Troubleshoot"},{"location":"setup/minio/","text":"Minio Minio event-source listens to minio bucket notifications and helps sensor trigger the workloads. Note : Minio event-source is exclusive for the Minio server. If you want to trigger workloads on AWS S3 bucket notification, please set up the AWS SNS event-source. Event Structure The structure of an event dispatched by the event-source over the eventbus looks like following, { context : { type : type_of_event_source , specversion : cloud_events_version , source : name_of_the_event_source , id : unique_event_id , time : event_time , datacontenttype : type_of_data , subject : name_of_the_configuration_within_event_source }, data : { notification: [ { /* Minio notification. More info is available at https://docs.min.io/docs/minio-bucket-notification-guide.html } ] } } Setup Make sure to have the minio server deployed and reachable from the event-source. If you are running Minio locally, make sure to port-forward to minio pod in order to make the service available outside local K8s cluster. kubectl -n argo-events port-forward minio-pod-name 9000:9000 Configure the minio client mc . mc config host add minio http://localhost:9000 minio minio123 Create a K8s secret that holds the access and secret key. This secret will be referred in the minio event source definition that we are going to install in a later step. apiVersion : v1 data : # base64 of minio accesskey : bWluaW8 = # base64 of minio123 secretkey : bWluaW8xMjM = kind : Secret metadata : name : artifacts - minio namespace : argo - events The event source we are going to use configures notifications for a bucket called input . mc mb minio/input Let's install event source in the argo-events namespace, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/minio.yaml Let's create the sensor, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/minio.yaml Create a file named and hello-world.txt and upload it onto to the input bucket. This will trigger the argo workflow. Run argo list to find the workflow. Troubleshoot Please read the FAQ .","title":"Minio"},{"location":"setup/minio/#minio","text":"Minio event-source listens to minio bucket notifications and helps sensor trigger the workloads. Note : Minio event-source is exclusive for the Minio server. If you want to trigger workloads on AWS S3 bucket notification, please set up the AWS SNS event-source.","title":"Minio"},{"location":"setup/minio/#event-structure","text":"The structure of an event dispatched by the event-source over the eventbus looks like following, { context : { type : type_of_event_source , specversion : cloud_events_version , source : name_of_the_event_source , id : unique_event_id , time : event_time , datacontenttype : type_of_data , subject : name_of_the_configuration_within_event_source }, data : { notification: [ { /* Minio notification. More info is available at https://docs.min.io/docs/minio-bucket-notification-guide.html } ] } }","title":"Event Structure"},{"location":"setup/minio/#setup","text":"Make sure to have the minio server deployed and reachable from the event-source. If you are running Minio locally, make sure to port-forward to minio pod in order to make the service available outside local K8s cluster. kubectl -n argo-events port-forward minio-pod-name 9000:9000 Configure the minio client mc . mc config host add minio http://localhost:9000 minio minio123 Create a K8s secret that holds the access and secret key. This secret will be referred in the minio event source definition that we are going to install in a later step. apiVersion : v1 data : # base64 of minio accesskey : bWluaW8 = # base64 of minio123 secretkey : bWluaW8xMjM = kind : Secret metadata : name : artifacts - minio namespace : argo - events The event source we are going to use configures notifications for a bucket called input . mc mb minio/input Let's install event source in the argo-events namespace, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/minio.yaml Let's create the sensor, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/minio.yaml Create a file named and hello-world.txt and upload it onto to the input bucket. This will trigger the argo workflow. Run argo list to find the workflow.","title":"Setup"},{"location":"setup/minio/#troubleshoot","text":"Please read the FAQ .","title":"Troubleshoot"},{"location":"setup/mqtt/","text":"MQTT The event-source listens to messages over MQTT and helps sensor trigger the workloads. Event Structure The structure of an event dispatched by the event-source over the eventbus looks like following, { context : { type : type_of_event_source , specversion : cloud_events_version , source : name_of_the_event_source , id : unique_event_id , time : event_time , datacontenttype : type_of_data , subject : name_of_the_configuration_within_event_source }, data : { topic : Topic refers to the MQTT topic name , messageId : MessageId is the unique ID for the message , body : Body is the message payload } } Specification MQTT event-source specification is available here . Setup Make sure to set up the MQTT Broker and Bridge in Kubernetes if you don't already have one. Create the event source by running the following command. Make sure to update the appropriate fields. kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/mqtt.yaml Create the sensor by running the following command, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/mqtt.yaml Send message by using MQTT client. Once a message is published, an argo workflow will be triggered. Run argo list to find the workflow. Troubleshoot Please read the FAQ .","title":"MQTT"},{"location":"setup/mqtt/#mqtt","text":"The event-source listens to messages over MQTT and helps sensor trigger the workloads.","title":"MQTT"},{"location":"setup/mqtt/#event-structure","text":"The structure of an event dispatched by the event-source over the eventbus looks like following, { context : { type : type_of_event_source , specversion : cloud_events_version , source : name_of_the_event_source , id : unique_event_id , time : event_time , datacontenttype : type_of_data , subject : name_of_the_configuration_within_event_source }, data : { topic : Topic refers to the MQTT topic name , messageId : MessageId is the unique ID for the message , body : Body is the message payload } }","title":"Event Structure"},{"location":"setup/mqtt/#specification","text":"MQTT event-source specification is available here .","title":"Specification"},{"location":"setup/mqtt/#setup","text":"Make sure to set up the MQTT Broker and Bridge in Kubernetes if you don't already have one. Create the event source by running the following command. Make sure to update the appropriate fields. kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/mqtt.yaml Create the sensor by running the following command, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/mqtt.yaml Send message by using MQTT client. Once a message is published, an argo workflow will be triggered. Run argo list to find the workflow.","title":"Setup"},{"location":"setup/mqtt/#troubleshoot","text":"Please read the FAQ .","title":"Troubleshoot"},{"location":"setup/nats/","text":"NATS NATS event-source listens to NATS subject notifications and helps sensor trigger the workloads. Event Structure The structure of an event dispatched by the event-source over the eventbus looks like following, { context : { type : type_of_event_source , specversion : cloud_events_version , source : name_of_the_event_source , id : unique_event_id , time : event_time , datacontenttype : type_of_data , subject : name_of_the_configuration_within_event_source }, data : { subject : name_of_the_nats_subject , body : message_payload } } Specification NATS event-source specification is available here . Setup Make sure to have NATS cluster deployed in the Kubernetes. If you don't have one already installed, please refer https://github.com/nats-io/nats-operator for details. NATS cluster setup for test purposes, apiVersion: v1 kind: Service metadata: name: nats namespace: argo-events labels: component: nats spec: selector: component: nats type: ClusterIP ports: - name: client port: 4222 - name: cluster port: 6222 - name: monitor port: 8222 --- apiVersion: apps/v1beta1 kind: StatefulSet metadata: name: nats namespace: argo-events labels: component: nats spec: serviceName: nats replicas: 1 template: metadata: labels: component: nats spec: serviceAccountName: argo-events-sa containers: - name: nats image: nats:latest ports: - containerPort: 4222 name: client - containerPort: 6222 name: cluster - containerPort: 8222 name: monitor livenessProbe: httpGet: path: / port: 8222 initialDelaySeconds: 10 timeoutSeconds: 5 Create the event source by running the following command. kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/nats.yaml Create the sensor by running the following command, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/nats.yaml If you are running NATS on local K8s cluster, make sure to port-forward to pod, kubectl -n argo-events port-forward nats-pod-name 4222:4222 Publish a message for the subject specified in the event source. Refer the nats example to publish a message to the subject https://github.com/nats-io/go-nats-examples/tree/master/patterns/publish-subscribe. go run main.go -s localhost foo { message : hello } Once a message is published, an argo workflow will be triggered. Run argo list to find the workflow. Troubleshoot Please read the FAQ .","title":"NATS"},{"location":"setup/nats/#nats","text":"NATS event-source listens to NATS subject notifications and helps sensor trigger the workloads.","title":"NATS"},{"location":"setup/nats/#event-structure","text":"The structure of an event dispatched by the event-source over the eventbus looks like following, { context : { type : type_of_event_source , specversion : cloud_events_version , source : name_of_the_event_source , id : unique_event_id , time : event_time , datacontenttype : type_of_data , subject : name_of_the_configuration_within_event_source }, data : { subject : name_of_the_nats_subject , body : message_payload } }","title":"Event Structure"},{"location":"setup/nats/#specification","text":"NATS event-source specification is available here .","title":"Specification"},{"location":"setup/nats/#setup","text":"Make sure to have NATS cluster deployed in the Kubernetes. If you don't have one already installed, please refer https://github.com/nats-io/nats-operator for details. NATS cluster setup for test purposes, apiVersion: v1 kind: Service metadata: name: nats namespace: argo-events labels: component: nats spec: selector: component: nats type: ClusterIP ports: - name: client port: 4222 - name: cluster port: 6222 - name: monitor port: 8222 --- apiVersion: apps/v1beta1 kind: StatefulSet metadata: name: nats namespace: argo-events labels: component: nats spec: serviceName: nats replicas: 1 template: metadata: labels: component: nats spec: serviceAccountName: argo-events-sa containers: - name: nats image: nats:latest ports: - containerPort: 4222 name: client - containerPort: 6222 name: cluster - containerPort: 8222 name: monitor livenessProbe: httpGet: path: / port: 8222 initialDelaySeconds: 10 timeoutSeconds: 5 Create the event source by running the following command. kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/nats.yaml Create the sensor by running the following command, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/nats.yaml If you are running NATS on local K8s cluster, make sure to port-forward to pod, kubectl -n argo-events port-forward nats-pod-name 4222:4222 Publish a message for the subject specified in the event source. Refer the nats example to publish a message to the subject https://github.com/nats-io/go-nats-examples/tree/master/patterns/publish-subscribe. go run main.go -s localhost foo { message : hello } Once a message is published, an argo workflow will be triggered. Run argo list to find the workflow.","title":"Setup"},{"location":"setup/nats/#troubleshoot","text":"Please read the FAQ .","title":"Troubleshoot"},{"location":"setup/nsq/","text":"NSQ NSQ event-source subscribes to nsq pub/sub notifications and helps sensor trigger the workloads. Event Structure The structure of an event dispatched by the event-source over the eventbus looks like following, { context : { type : type_of_event_source , specversion : cloud_events_version , source : name_of_the_event_source , id : unique_event_id , time : event_time , datacontenttype : type_of_data , subject : name_of_the_configuration_within_event_source }, data : { body : Body is the message data , timestamp : timestamp of the message , nsqdAddress : NSQDAddress is the address of the nsq host } } Specification NSQ event-source is available here . Setup Deploy NSQ on local K8s cluster apiVersion : v1 kind : Service metadata : name : nsqlookupd labels : app : nsq spec : ports : - port : 4160 targetPort : 4160 name : tcp - port : 4161 targetPort : 4161 name : http clusterIP : None selector : app : nsq component : nsqlookupd --- apiVersion : v1 kind : Service metadata : name : nsqd labels : app : nsq spec : ports : - port : 4150 targetPort : 4150 name : tcp - port : 4151 targetPort : 4151 name : http clusterIP : None selector : app : nsq component : nsqd --- apiVersion : v1 kind : Service metadata : name : nsqadmin labels : app : nsq spec : ports : - port : 4170 targetPort : 4170 name : tcp - port : 4171 targetPort : 4171 name : http selector : app : nsq component : nsqadmin --- apiVersion : apps / v1beta1 kind : StatefulSet metadata : name : nsqlookupd spec : serviceName : nsqlookupd replicas : 1 updateStrategy : type : RollingUpdate template : metadata : labels : app : nsq component : nsqlookupd spec : containers : - name : nsqlookupd image : nsqio / nsq : v1 . 1.0 imagePullPolicy : Always resources : requests : cpu : 30 m memory : 64 Mi ports : - containerPort : 4160 name : tcp - containerPort : 4161 name : http livenessProbe : httpGet : path : / ping port : http initialDelaySeconds : 5 readinessProbe : httpGet : path : / ping port : http initialDelaySeconds : 2 command : - / nsqlookupd terminationGracePeriodSeconds : 5 --- apiVersion : apps / v1beta1 kind : Deployment metadata : name : nsqd spec : replicas : 1 selector : matchLabels : app : nsq component : nsqd template : metadata : labels : app : nsq component : nsqd spec : containers : - name : nsqd image : nsqio / nsq : v1 . 1.0 imagePullPolicy : Always resources : requests : cpu : 30 m memory : 64 Mi ports : - containerPort : 4150 name : tcp - containerPort : 4151 name : http livenessProbe : httpGet : path : / ping port : http initialDelaySeconds : 5 readinessProbe : httpGet : path : / ping port : http initialDelaySeconds : 2 volumeMounts : - name : datadir mountPath : / data command : - / nsqd - - data - path - / data - - lookupd - tcp - address - nsqlookupd . argo - events . svc : 4160 - - broadcast - address - nsqd . argo - events . svc env : - name : HOSTNAME valueFrom : fieldRef : fieldPath : metadata . name terminationGracePeriodSeconds : 5 volumes : - name : datadir emptyDir : {} --- apiVersion : extensions / v1beta1 kind : Deployment metadata : name : nsqadmin spec : replicas : 1 template : metadata : labels : app : nsq component : nsqadmin spec : containers : - name : nsqadmin image : nsqio / nsq : v1 . 1.0 imagePullPolicy : Always resources : requests : cpu : 30 m memory : 64 Mi ports : - containerPort : 4170 name : tcp - containerPort : 4171 name : http livenessProbe : httpGet : path : / ping port : http initialDelaySeconds : 10 readinessProbe : httpGet : path : / ping port : http initialDelaySeconds : 5 command : - / nsqadmin - - lookupd - http - address - nsqlookupd . argo - events . svc : 4161 terminationGracePeriodSeconds : 5 Expose NSQD by kubectl port-forward , kubectl -n argo-events port-forward service/nsqd 4151:4151 Create topic hello and channel my-channel curl -X POST http://localhost:4151/topic/create?topic=hello curl -X POST http://localhost:4151/channel/create?topic=hello channel=my-channel Create the event source by running the following command. kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/nsq.yaml Create the sensor by running the following command, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/nsq.yaml Publish a message on topic hello and channel my-channel , curl -d { message : hello } http://localhost:4151/pub?topic=hello channel=my-channel Once a message is published, an argo workflow will be triggered. Run argo list to find the workflow. Troubleshoot Please read the FAQ .","title":"NSQ"},{"location":"setup/nsq/#nsq","text":"NSQ event-source subscribes to nsq pub/sub notifications and helps sensor trigger the workloads.","title":"NSQ"},{"location":"setup/nsq/#event-structure","text":"The structure of an event dispatched by the event-source over the eventbus looks like following, { context : { type : type_of_event_source , specversion : cloud_events_version , source : name_of_the_event_source , id : unique_event_id , time : event_time , datacontenttype : type_of_data , subject : name_of_the_configuration_within_event_source }, data : { body : Body is the message data , timestamp : timestamp of the message , nsqdAddress : NSQDAddress is the address of the nsq host } }","title":"Event Structure"},{"location":"setup/nsq/#specification","text":"NSQ event-source is available here .","title":"Specification"},{"location":"setup/nsq/#setup","text":"Deploy NSQ on local K8s cluster apiVersion : v1 kind : Service metadata : name : nsqlookupd labels : app : nsq spec : ports : - port : 4160 targetPort : 4160 name : tcp - port : 4161 targetPort : 4161 name : http clusterIP : None selector : app : nsq component : nsqlookupd --- apiVersion : v1 kind : Service metadata : name : nsqd labels : app : nsq spec : ports : - port : 4150 targetPort : 4150 name : tcp - port : 4151 targetPort : 4151 name : http clusterIP : None selector : app : nsq component : nsqd --- apiVersion : v1 kind : Service metadata : name : nsqadmin labels : app : nsq spec : ports : - port : 4170 targetPort : 4170 name : tcp - port : 4171 targetPort : 4171 name : http selector : app : nsq component : nsqadmin --- apiVersion : apps / v1beta1 kind : StatefulSet metadata : name : nsqlookupd spec : serviceName : nsqlookupd replicas : 1 updateStrategy : type : RollingUpdate template : metadata : labels : app : nsq component : nsqlookupd spec : containers : - name : nsqlookupd image : nsqio / nsq : v1 . 1.0 imagePullPolicy : Always resources : requests : cpu : 30 m memory : 64 Mi ports : - containerPort : 4160 name : tcp - containerPort : 4161 name : http livenessProbe : httpGet : path : / ping port : http initialDelaySeconds : 5 readinessProbe : httpGet : path : / ping port : http initialDelaySeconds : 2 command : - / nsqlookupd terminationGracePeriodSeconds : 5 --- apiVersion : apps / v1beta1 kind : Deployment metadata : name : nsqd spec : replicas : 1 selector : matchLabels : app : nsq component : nsqd template : metadata : labels : app : nsq component : nsqd spec : containers : - name : nsqd image : nsqio / nsq : v1 . 1.0 imagePullPolicy : Always resources : requests : cpu : 30 m memory : 64 Mi ports : - containerPort : 4150 name : tcp - containerPort : 4151 name : http livenessProbe : httpGet : path : / ping port : http initialDelaySeconds : 5 readinessProbe : httpGet : path : / ping port : http initialDelaySeconds : 2 volumeMounts : - name : datadir mountPath : / data command : - / nsqd - - data - path - / data - - lookupd - tcp - address - nsqlookupd . argo - events . svc : 4160 - - broadcast - address - nsqd . argo - events . svc env : - name : HOSTNAME valueFrom : fieldRef : fieldPath : metadata . name terminationGracePeriodSeconds : 5 volumes : - name : datadir emptyDir : {} --- apiVersion : extensions / v1beta1 kind : Deployment metadata : name : nsqadmin spec : replicas : 1 template : metadata : labels : app : nsq component : nsqadmin spec : containers : - name : nsqadmin image : nsqio / nsq : v1 . 1.0 imagePullPolicy : Always resources : requests : cpu : 30 m memory : 64 Mi ports : - containerPort : 4170 name : tcp - containerPort : 4171 name : http livenessProbe : httpGet : path : / ping port : http initialDelaySeconds : 10 readinessProbe : httpGet : path : / ping port : http initialDelaySeconds : 5 command : - / nsqadmin - - lookupd - http - address - nsqlookupd . argo - events . svc : 4161 terminationGracePeriodSeconds : 5 Expose NSQD by kubectl port-forward , kubectl -n argo-events port-forward service/nsqd 4151:4151 Create topic hello and channel my-channel curl -X POST http://localhost:4151/topic/create?topic=hello curl -X POST http://localhost:4151/channel/create?topic=hello channel=my-channel Create the event source by running the following command. kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/nsq.yaml Create the sensor by running the following command, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/nsq.yaml Publish a message on topic hello and channel my-channel , curl -d { message : hello } http://localhost:4151/pub?topic=hello channel=my-channel Once a message is published, an argo workflow will be triggered. Run argo list to find the workflow.","title":"Setup"},{"location":"setup/nsq/#troubleshoot","text":"Please read the FAQ .","title":"Troubleshoot"},{"location":"setup/redis/","text":"Redis Redis event-source subscribes to Redis publisher and helps sensor trigger workloads. Event Structure The structure of an event dispatched by the event-source over the eventbus looks like following, { context : { type : type_of_event_source , specversion : cloud_events_version , source : name_of_the_event_source , id : unique_event_id , time : event_time , datacontenttype : type_of_data , subject : name_of_the_configuration_within_event_source }, data : { channel : Subscription channel , pattern : Message pattern , body : message body // string } } Specification Redis event-source specification is available here . Setup Follow the documentation to set up Redis database. Create the event source by running the following command. kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/redis.yaml Create the sensor by running the following command, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/redis.yaml Log into redis pod using kubectl , kubectl -n argo-events exec -it redis-pod-name -c redis-container-name -- /bin/bash Run redis-cli and publish a message on FOO channel. PUBLISH FOO hello Once a message is published, an argo workflow will be triggered. Run argo list to find the workflow. Troubleshoot Please read the FAQ .","title":"Redis"},{"location":"setup/redis/#redis","text":"Redis event-source subscribes to Redis publisher and helps sensor trigger workloads.","title":"Redis"},{"location":"setup/redis/#event-structure","text":"The structure of an event dispatched by the event-source over the eventbus looks like following, { context : { type : type_of_event_source , specversion : cloud_events_version , source : name_of_the_event_source , id : unique_event_id , time : event_time , datacontenttype : type_of_data , subject : name_of_the_configuration_within_event_source }, data : { channel : Subscription channel , pattern : Message pattern , body : message body // string } }","title":"Event Structure"},{"location":"setup/redis/#specification","text":"Redis event-source specification is available here .","title":"Specification"},{"location":"setup/redis/#setup","text":"Follow the documentation to set up Redis database. Create the event source by running the following command. kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/redis.yaml Create the sensor by running the following command, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/redis.yaml Log into redis pod using kubectl , kubectl -n argo-events exec -it redis-pod-name -c redis-container-name -- /bin/bash Run redis-cli and publish a message on FOO channel. PUBLISH FOO hello Once a message is published, an argo workflow will be triggered. Run argo list to find the workflow.","title":"Setup"},{"location":"setup/redis/#troubleshoot","text":"Please read the FAQ .","title":"Troubleshoot"},{"location":"setup/resource/","text":"Resource Resource event-source watches change notifications for K8s object and helps sensor trigger the workloads. Event Structure The structure of an event dispatched by the event-source over the eventbus looks like following, { context : { type : type_of_event_source , specversion : cloud_events_version , source : name_of_the_event_source , id : unique_event_id , time : event_time , datacontenttype : type_of_data , subject : name_of_the_configuration_within_event_source }, data : { type : type_of_the_event , // ADD, UPDATE or DELETE body : resource_body , // JSON format group : resource_group_name , version : resource_version_name , resource : resource_name } } Specification Resource event-source specification is available here . Setup Create the event source by running the following command. kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/resource.yaml Create the sensor by running the following command, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/resource.yaml The event source we created in step 1 contains configuration which makes the event-source listen to Argo workflows marked with label app: my-workflow . Lets create a workflow called my-workflow with label app: my-workflow apiVersion : argoproj . io / v1alpha1 kind : Workflow metadata : name : my - workflow labels : app : my - workflow spec : entrypoint : whalesay templates : - name : whalesay container : image : docker / whalesay : latest command : [ cowsay ] args : [ hello world ] Once the my-workflow is created, the sensor will trigger the workflow. Run argo list to list the triggered workflow. List Options The Resource Event-Source allows to configure the list options through labels and field selectors for setting up a watch on objects. In the example above, we had set up the list option as follows, filter: # labels and filters are meant to provide K8s API options to filter the object list that are being watched. # Please read https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#api for more details. # labels provide listing options to K8s API to watch objects labels: - key: app # Supported operations like ==, !=, etc. # Defaults to ==. # Refer https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#label-selectors for more info. # optional. operation: == value: my-workflow The key-operation-value items under the filter - labels are used by the event-source to filter the objects that are eligible for the watch. So, in the present case, the event-source will set up a watch for those objects who have label \"app: my-workflow\". You can add more key-operation-value items to the list as per your use-case. Similarly, you can pass field selectors to the watch list options, e.g., filter: # labels and filters are meant to provide K8s API options to filter the object list that are being watched. # Please read https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#api for more details. # fields provide listing options to K8s API to watch objects fields: - key: metadata.name # Supported operations like ==, !=, =, = etc. # Defaults to ==. # Refer https://kubernetes.io/docs/concepts/overview/working-with-objects/field-selectors/ for more info. # optional. operation: == value: my-workflow Note: The label and fields under filter are used at the time of setting up the watch by the event-source. If you want to filter the objects based on the annotations or some other fields, use the Data Filters available in the sensor. Troubleshoot Please read the FAQ .","title":"Resource"},{"location":"setup/resource/#resource","text":"Resource event-source watches change notifications for K8s object and helps sensor trigger the workloads.","title":"Resource"},{"location":"setup/resource/#event-structure","text":"The structure of an event dispatched by the event-source over the eventbus looks like following, { context : { type : type_of_event_source , specversion : cloud_events_version , source : name_of_the_event_source , id : unique_event_id , time : event_time , datacontenttype : type_of_data , subject : name_of_the_configuration_within_event_source }, data : { type : type_of_the_event , // ADD, UPDATE or DELETE body : resource_body , // JSON format group : resource_group_name , version : resource_version_name , resource : resource_name } }","title":"Event Structure"},{"location":"setup/resource/#specification","text":"Resource event-source specification is available here .","title":"Specification"},{"location":"setup/resource/#setup","text":"Create the event source by running the following command. kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/resource.yaml Create the sensor by running the following command, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/resource.yaml The event source we created in step 1 contains configuration which makes the event-source listen to Argo workflows marked with label app: my-workflow . Lets create a workflow called my-workflow with label app: my-workflow apiVersion : argoproj . io / v1alpha1 kind : Workflow metadata : name : my - workflow labels : app : my - workflow spec : entrypoint : whalesay templates : - name : whalesay container : image : docker / whalesay : latest command : [ cowsay ] args : [ hello world ] Once the my-workflow is created, the sensor will trigger the workflow. Run argo list to list the triggered workflow.","title":"Setup"},{"location":"setup/resource/#list-options","text":"The Resource Event-Source allows to configure the list options through labels and field selectors for setting up a watch on objects. In the example above, we had set up the list option as follows, filter: # labels and filters are meant to provide K8s API options to filter the object list that are being watched. # Please read https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#api for more details. # labels provide listing options to K8s API to watch objects labels: - key: app # Supported operations like ==, !=, etc. # Defaults to ==. # Refer https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#label-selectors for more info. # optional. operation: == value: my-workflow The key-operation-value items under the filter - labels are used by the event-source to filter the objects that are eligible for the watch. So, in the present case, the event-source will set up a watch for those objects who have label \"app: my-workflow\". You can add more key-operation-value items to the list as per your use-case. Similarly, you can pass field selectors to the watch list options, e.g., filter: # labels and filters are meant to provide K8s API options to filter the object list that are being watched. # Please read https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#api for more details. # fields provide listing options to K8s API to watch objects fields: - key: metadata.name # Supported operations like ==, !=, =, = etc. # Defaults to ==. # Refer https://kubernetes.io/docs/concepts/overview/working-with-objects/field-selectors/ for more info. # optional. operation: == value: my-workflow Note: The label and fields under filter are used at the time of setting up the watch by the event-source. If you want to filter the objects based on the annotations or some other fields, use the Data Filters available in the sensor.","title":"List Options"},{"location":"setup/resource/#troubleshoot","text":"Please read the FAQ .","title":"Troubleshoot"},{"location":"setup/webhook/","text":"Webhook Webhook event-source exposes a http server and allows external entities to trigger workloads via http requests. Event Structure The structure of an event dispatched by the event-source to the sensor looks like following, { context : { type : type_of_event_source , specversion : cloud_events_version , source : name_of_the_event_source , id : unique_event_id , time : event_time , datacontenttype : type_of_data , subject : name_of_the_configuration_within_event_source }, data : { header : {/* the headers from the request received by the event-source from the external entity */}, body : { /* the payload of the request received by the event-source from the external entity */}, } } Specification Webhook event-source specification is available here . Setup Install the event source in the argo-events namespace, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/webhook.yaml The event-source pod is listening for HTTP requests on port 12000 and endpoint /example . It's time to create the sensor, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/webhook.yaml Once the sensor pod is in running state, test the setup by sending a POST request to event-source service. Troubleshoot Please read the FAQ .","title":"Webhook"},{"location":"setup/webhook/#webhook","text":"Webhook event-source exposes a http server and allows external entities to trigger workloads via http requests.","title":"Webhook"},{"location":"setup/webhook/#event-structure","text":"The structure of an event dispatched by the event-source to the sensor looks like following, { context : { type : type_of_event_source , specversion : cloud_events_version , source : name_of_the_event_source , id : unique_event_id , time : event_time , datacontenttype : type_of_data , subject : name_of_the_configuration_within_event_source }, data : { header : {/* the headers from the request received by the event-source from the external entity */}, body : { /* the payload of the request received by the event-source from the external entity */}, } }","title":"Event Structure"},{"location":"setup/webhook/#specification","text":"Webhook event-source specification is available here .","title":"Specification"},{"location":"setup/webhook/#setup","text":"Install the event source in the argo-events namespace, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/webhook.yaml The event-source pod is listening for HTTP requests on port 12000 and endpoint /example . It's time to create the sensor, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/webhook.yaml Once the sensor pod is in running state, test the setup by sending a POST request to event-source service.","title":"Setup"},{"location":"setup/webhook/#troubleshoot","text":"Please read the FAQ .","title":"Troubleshoot"},{"location":"triggers/argo-workflow/","text":"Argo Workflow Trigger Argo workflow is K8s custom resource which help orchestrating parallel jobs on Kubernetes. Trigger a workflow Make sure to have the eventbus deployed in the namespace. We will use webhook event-source and sensor to trigger an Argo workflow. Let's set up a webhook event-source to process incoming requests. kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/webhook.yaml Create the sensor, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/webhook.yaml Let's expose the webhook event-source pod using port-forward so that we can make a request to it. kubectl -n argo-events port-forward name-of-event-source-pod 12000:12000 Use either Curl or Postman to send a post request to the http://localhost:12000/example curl -d { message : ok } -H Content-Type: application/json -X POST http://localhost:12000/example List the workflow using argo list . Parameterization Similar to other type of triggers, sensor offers parameterization for the Argo workflow trigger. Parameterization is specially useful when you want to define a generic trigger template in the sensor and populate the workflow object values on the fly. You can learn more about trigger parameterization here . Policy Trigger policy helps you determine the status of the triggered Argo workflow object and decide whether to stop or continue sensor. Take a look at K8s Trigger Policy . Argo CLI Although the sensor defined above lets you trigger an Argo workflow, it doesn't have the ability to leverage the functionality provided by the Argo CLI such as, Submit Resubmit Resume Retry Suspend To make use of Argo CLI operations, The sensor provides the argoWorkflow trigger template, argoWorkflow: group: argoproj.io version: v1alpha1 resource: workflows operation: submit # submit, resubmit, resume, retry or suspend Complete example is available here .","title":"Argo Workflow Trigger"},{"location":"triggers/argo-workflow/#argo-workflow-trigger","text":"Argo workflow is K8s custom resource which help orchestrating parallel jobs on Kubernetes.","title":"Argo Workflow Trigger"},{"location":"triggers/argo-workflow/#trigger-a-workflow","text":"Make sure to have the eventbus deployed in the namespace. We will use webhook event-source and sensor to trigger an Argo workflow. Let's set up a webhook event-source to process incoming requests. kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/webhook.yaml Create the sensor, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/webhook.yaml Let's expose the webhook event-source pod using port-forward so that we can make a request to it. kubectl -n argo-events port-forward name-of-event-source-pod 12000:12000 Use either Curl or Postman to send a post request to the http://localhost:12000/example curl -d { message : ok } -H Content-Type: application/json -X POST http://localhost:12000/example List the workflow using argo list .","title":"Trigger a workflow"},{"location":"triggers/argo-workflow/#parameterization","text":"Similar to other type of triggers, sensor offers parameterization for the Argo workflow trigger. Parameterization is specially useful when you want to define a generic trigger template in the sensor and populate the workflow object values on the fly. You can learn more about trigger parameterization here .","title":"Parameterization"},{"location":"triggers/argo-workflow/#policy","text":"Trigger policy helps you determine the status of the triggered Argo workflow object and decide whether to stop or continue sensor. Take a look at K8s Trigger Policy .","title":"Policy"},{"location":"triggers/argo-workflow/#argo-cli","text":"Although the sensor defined above lets you trigger an Argo workflow, it doesn't have the ability to leverage the functionality provided by the Argo CLI such as, Submit Resubmit Resume Retry Suspend To make use of Argo CLI operations, The sensor provides the argoWorkflow trigger template, argoWorkflow: group: argoproj.io version: v1alpha1 resource: workflows operation: submit # submit, resubmit, resume, retry or suspend Complete example is available here .","title":"Argo CLI"},{"location":"triggers/aws-lambda/","text":"AWS Lambda AWS Lambda provides a tremendous value, but the event driven lambda invocation is limited to SNS, SQS and few other event sources. Argo Events makes it easy to integrate lambda with event sources that are not native to AWS. Trigger A Simple Lambda Make sure to have eventbus deployed in the namespace. Make sure your AWS account has permissions to execute Lambda. More info on AWS permissions is available here . Fetch your access and secret key for AWS account and base64 encode them. Create a secret called aws-secret as follows, apiVersion : v1 kind : Secret metadata : name : aws - secret type : Opaque data : accesskey : base64 - access - key secretkey : base64 - secret - key Create a basic lambda function called hello either using AWS cli or console. exports.handler = async (event, context) = { console.log( name = , event.name); return event.name; }; Let's set up webhook event-source to invoke the lambda over http requests. kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/webhook.yaml Let's expose the webhook event-source using port-forward so that we can make a request to it. kubectl -n argo-events port-forward name-of-event-source-pod 12000:12000 Deploy the webhook sensor with AWS Lambda trigger kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/aws-lambda-trigger.yaml Once the sensor pod is in running state, make a curl request to webhook event-source pod, curl -d { name : foo } -H Content-Type: application/json -X POST http://localhost:12000/example It will trigger the AWS Lambda function hello . Look at the CloudWatch logs to verify. Specification The AWS Lambda trigger specification is available here . Request Payload Invoking the AWS Lambda without a request payload would not be very useful. The lambda trigger within a sensor is invoked when sensor receives an event from the eventbus. In order to construct a request payload based on the event data, sensor offers payload field as a part of the lambda trigger. Let's examine a lambda trigger, awsLambda: functionName: hello accessKey: name: aws-secret key: accesskey secretKey: name: aws-secret key: secretkey namespace: argo-events region: us-east-1 payload: - src: dependencyName: test-dep dataKey: body.name dest: name The payload contains the list of src which refers to the source event and dest which refers to destination key within result request payload. The payload declared above will generate a request payload like below, { name : foo // name field from event data } The above payload will be passed in the request to invoke the AWS lambda. You can add however many number of src and dest under payload . Note : Take a look at Parameterization in order to understand how to extract particular key-value from event data. Parameterization Similar to other type of triggers, sensor offers parameterization for the AWS Lambda trigger. Parameterization is specially useful when you want to define a generic trigger template in the sensor and populate values like function name, payload values on the fly. Consider a scenario where you don't want to hard-code the function name and let the event data populate it. awsLambda: functionName: hello // this will be replaced. accessKey: name: aws-secret key: accesskey secretKey: name: aws-secret key: secretkey namespace: argo-events region: us-east-1 payload: - src: dependencyName: test-dep dataKey: body.message dest: message parameters: - src: dependencyName: test-dep dataKey: body.function_name dest: functionName With parameters the sensor will replace the function name hello with the value of field function_name from event data. You can learn more about trigger parameterization here . Policy Trigger policy helps you determine the status of the lambda invocation and decide whether to stop or continue sensor. To determine whether the lamda was successful or not, Lambda trigger provides a Status policy. The Status holds a list of response statuses that are considered valid. awsLambda: functionName: hello accessKey: name: aws-secret key: accesskey secretKey: name: aws-secret key: secretkey namespace: argo-events region: us-east-1 payload: - src: dependencyName: test-dep dataKey: body.message dest: message policy: status: allow: - 200 - 201 The above lambda trigger will be treated successful only if its invocation returns with either 200 or 201 status.","title":"AWS Lambda"},{"location":"triggers/aws-lambda/#aws-lambda","text":"AWS Lambda provides a tremendous value, but the event driven lambda invocation is limited to SNS, SQS and few other event sources. Argo Events makes it easy to integrate lambda with event sources that are not native to AWS.","title":"AWS Lambda"},{"location":"triggers/aws-lambda/#trigger-a-simple-lambda","text":"Make sure to have eventbus deployed in the namespace. Make sure your AWS account has permissions to execute Lambda. More info on AWS permissions is available here . Fetch your access and secret key for AWS account and base64 encode them. Create a secret called aws-secret as follows, apiVersion : v1 kind : Secret metadata : name : aws - secret type : Opaque data : accesskey : base64 - access - key secretkey : base64 - secret - key Create a basic lambda function called hello either using AWS cli or console. exports.handler = async (event, context) = { console.log( name = , event.name); return event.name; }; Let's set up webhook event-source to invoke the lambda over http requests. kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/webhook.yaml Let's expose the webhook event-source using port-forward so that we can make a request to it. kubectl -n argo-events port-forward name-of-event-source-pod 12000:12000 Deploy the webhook sensor with AWS Lambda trigger kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/aws-lambda-trigger.yaml Once the sensor pod is in running state, make a curl request to webhook event-source pod, curl -d { name : foo } -H Content-Type: application/json -X POST http://localhost:12000/example It will trigger the AWS Lambda function hello . Look at the CloudWatch logs to verify.","title":"Trigger A Simple Lambda"},{"location":"triggers/aws-lambda/#specification","text":"The AWS Lambda trigger specification is available here .","title":"Specification"},{"location":"triggers/aws-lambda/#request-payload","text":"Invoking the AWS Lambda without a request payload would not be very useful. The lambda trigger within a sensor is invoked when sensor receives an event from the eventbus. In order to construct a request payload based on the event data, sensor offers payload field as a part of the lambda trigger. Let's examine a lambda trigger, awsLambda: functionName: hello accessKey: name: aws-secret key: accesskey secretKey: name: aws-secret key: secretkey namespace: argo-events region: us-east-1 payload: - src: dependencyName: test-dep dataKey: body.name dest: name The payload contains the list of src which refers to the source event and dest which refers to destination key within result request payload. The payload declared above will generate a request payload like below, { name : foo // name field from event data } The above payload will be passed in the request to invoke the AWS lambda. You can add however many number of src and dest under payload . Note : Take a look at Parameterization in order to understand how to extract particular key-value from event data.","title":"Request Payload"},{"location":"triggers/aws-lambda/#parameterization","text":"Similar to other type of triggers, sensor offers parameterization for the AWS Lambda trigger. Parameterization is specially useful when you want to define a generic trigger template in the sensor and populate values like function name, payload values on the fly. Consider a scenario where you don't want to hard-code the function name and let the event data populate it. awsLambda: functionName: hello // this will be replaced. accessKey: name: aws-secret key: accesskey secretKey: name: aws-secret key: secretkey namespace: argo-events region: us-east-1 payload: - src: dependencyName: test-dep dataKey: body.message dest: message parameters: - src: dependencyName: test-dep dataKey: body.function_name dest: functionName With parameters the sensor will replace the function name hello with the value of field function_name from event data. You can learn more about trigger parameterization here .","title":"Parameterization"},{"location":"triggers/aws-lambda/#policy","text":"Trigger policy helps you determine the status of the lambda invocation and decide whether to stop or continue sensor. To determine whether the lamda was successful or not, Lambda trigger provides a Status policy. The Status holds a list of response statuses that are considered valid. awsLambda: functionName: hello accessKey: name: aws-secret key: accesskey secretKey: name: aws-secret key: secretkey namespace: argo-events region: us-east-1 payload: - src: dependencyName: test-dep dataKey: body.message dest: message policy: status: allow: - 200 - 201 The above lambda trigger will be treated successful only if its invocation returns with either 200 or 201 status.","title":"Policy"},{"location":"triggers/build-your-own-trigger/","text":"Build Your Own Trigger Argo Events supports a variety of triggers out of box like Argo Workflow, K8s Objects, AWS Lambda, HTTP Requests etc., but you may want to write your own logic to trigger a pipeline or create an object in K8s cluster. An example would be to trigger TektonCD or AirFlow pipelines on GitHub events. Custom Trigger In order to plug your own implementation for a trigger with Argo Events Sensor, you need to run a gRPC server that implements the interface that the sensor expects. Interface The interface exposed via proto file, // Trigger offers services to build a custom trigger service Trigger { // FetchResource fetches the resource to be triggered. rpc FetchResource(FetchResourceRequest) returns (FetchResourceResponse); // Execute executes the requested trigger resource. rpc Execute(ExecuteRequest) returns (ExecuteResponse); // ApplyPolicy applies policies on the trigger execution result. rpc ApplyPolicy(ApplyPolicyRequest) returns (ApplyPolicyResponse); } The complete proto file is available here . Let's walk through the contract, FetchResource : If the trigger server needs to fetch a resource from external sources like S3, Git or a URL, this is the place to do so. e.g. if the trigger server aims to invoke a TektonCD pipeline and the PipelineRun resource lives on Git, then trigger server can first fetch it from Git and return it back to sensor. Execute : In this method, the trigger server executes/invokes the trigger. e.g. TektonCD pipeline resource being created in K8s cluster. ApplyPolicy : This is where your trigger implementation can check whether the triggered resource transitioned into the success state. Depending upon the response from the trigger server, the sensor will either stop processing subsequent triggers, or it will continue to process them. How to define the Custom Trigger in a sensor? Let's look at the following sensor, apiVersion: argoproj.io/v1alpha1 kind: Sensor metadata: name: webhook-sensor spec: template: spec: containers: - name: sensor image: metalgearsolid/sensor:v0.15.0 imagePullPolicy: Always serviceAccountName: argo-events-sa dependencies: - name: test-dep eventSourceName: webhook eventName: example subscription: http: port: 9300 triggers: - template: name: webhook-workflow-trigger custom: # the url of the trigger server. serverURL: tekton-trigger.argo-events.svc:9000 # spec is map of string- string and it is sent over to trigger server. # the spec can be anything you want as per your use-case, just make sure the trigger server understands the spec map. spec: url: https://raw.githubusercontent.com/VaibhavPage/tekton-cd-trigger/master/example.yaml # These parameters are applied on resource fetched and returned by the trigger server. # e.g. consider a trigger server which invokes TektonCD pipeline runs, then # the trigger server can return a TektonCD PipelineRun resource. # The parameters are then applied on that PipelineRun resource. parameters: - src: dependencyName: test-dep dataKey: body.namespace dest: metadata.namespace # These parameters are applied on entire template body. # So that you can parameterize anything under `custom` key such as `serverURL`, `spec` etc. parameters: - src: dependencyName: test-dep dataKey: body.url dest: custom.spec.url The sensor definition should look familiar to you. The only difference is the custom key under triggers - template . The specification under custom key defines the custom trigger. The most important fields are, serverURL : This is the URL of the trigger gRPC server. spec : It is a map of string - string. The spec can be anything you want as per your use-case. The sensor sends the spec to trigger server, and it is upto the trigger gRPC server to interpret the spec. parameters : The parameters override the resource that is fetched by the trigger server. Read more info on parameters here . payload : Payload to send to the trigger server. Read more on payload here . The complete spec for the custom trigger is available here . Custom Trigger in Action Refer to a sample trigger server that invokes TektonCD pipeline on events.","title":"Build Your Own Trigger"},{"location":"triggers/build-your-own-trigger/#build-your-own-trigger","text":"Argo Events supports a variety of triggers out of box like Argo Workflow, K8s Objects, AWS Lambda, HTTP Requests etc., but you may want to write your own logic to trigger a pipeline or create an object in K8s cluster. An example would be to trigger TektonCD or AirFlow pipelines on GitHub events.","title":"Build Your Own Trigger"},{"location":"triggers/build-your-own-trigger/#custom-trigger","text":"In order to plug your own implementation for a trigger with Argo Events Sensor, you need to run a gRPC server that implements the interface that the sensor expects.","title":"Custom Trigger"},{"location":"triggers/build-your-own-trigger/#interface","text":"The interface exposed via proto file, // Trigger offers services to build a custom trigger service Trigger { // FetchResource fetches the resource to be triggered. rpc FetchResource(FetchResourceRequest) returns (FetchResourceResponse); // Execute executes the requested trigger resource. rpc Execute(ExecuteRequest) returns (ExecuteResponse); // ApplyPolicy applies policies on the trigger execution result. rpc ApplyPolicy(ApplyPolicyRequest) returns (ApplyPolicyResponse); } The complete proto file is available here . Let's walk through the contract, FetchResource : If the trigger server needs to fetch a resource from external sources like S3, Git or a URL, this is the place to do so. e.g. if the trigger server aims to invoke a TektonCD pipeline and the PipelineRun resource lives on Git, then trigger server can first fetch it from Git and return it back to sensor. Execute : In this method, the trigger server executes/invokes the trigger. e.g. TektonCD pipeline resource being created in K8s cluster. ApplyPolicy : This is where your trigger implementation can check whether the triggered resource transitioned into the success state. Depending upon the response from the trigger server, the sensor will either stop processing subsequent triggers, or it will continue to process them.","title":"Interface"},{"location":"triggers/build-your-own-trigger/#how-to-define-the-custom-trigger-in-a-sensor","text":"Let's look at the following sensor, apiVersion: argoproj.io/v1alpha1 kind: Sensor metadata: name: webhook-sensor spec: template: spec: containers: - name: sensor image: metalgearsolid/sensor:v0.15.0 imagePullPolicy: Always serviceAccountName: argo-events-sa dependencies: - name: test-dep eventSourceName: webhook eventName: example subscription: http: port: 9300 triggers: - template: name: webhook-workflow-trigger custom: # the url of the trigger server. serverURL: tekton-trigger.argo-events.svc:9000 # spec is map of string- string and it is sent over to trigger server. # the spec can be anything you want as per your use-case, just make sure the trigger server understands the spec map. spec: url: https://raw.githubusercontent.com/VaibhavPage/tekton-cd-trigger/master/example.yaml # These parameters are applied on resource fetched and returned by the trigger server. # e.g. consider a trigger server which invokes TektonCD pipeline runs, then # the trigger server can return a TektonCD PipelineRun resource. # The parameters are then applied on that PipelineRun resource. parameters: - src: dependencyName: test-dep dataKey: body.namespace dest: metadata.namespace # These parameters are applied on entire template body. # So that you can parameterize anything under `custom` key such as `serverURL`, `spec` etc. parameters: - src: dependencyName: test-dep dataKey: body.url dest: custom.spec.url The sensor definition should look familiar to you. The only difference is the custom key under triggers - template . The specification under custom key defines the custom trigger. The most important fields are, serverURL : This is the URL of the trigger gRPC server. spec : It is a map of string - string. The spec can be anything you want as per your use-case. The sensor sends the spec to trigger server, and it is upto the trigger gRPC server to interpret the spec. parameters : The parameters override the resource that is fetched by the trigger server. Read more info on parameters here . payload : Payload to send to the trigger server. Read more on payload here . The complete spec for the custom trigger is available here .","title":"How to define the Custom Trigger in a sensor?"},{"location":"triggers/build-your-own-trigger/#custom-trigger-in-action","text":"Refer to a sample trigger server that invokes TektonCD pipeline on events.","title":"Custom Trigger in Action"},{"location":"triggers/http-trigger/","text":"HTTP Trigger Argo Events offers HTTP trigger which can easily invoke serverless functions like OpenFaas, Kubeless, Knative, Nuclio and make REST API calls. Specification The HTTP trigger specification is available here . REST API Calls Consider a scenario where your REST API server needs to consume events from event-sources S3, GitHub, SQS etc. Usually, you'd end up writing the integration yourself in the server code, although server logic has nothing to do any of the event-sources. This is where Argo Events HTTP trigger can hel. The HTTP trigger takes the task of consuming events from event-sources away from API server and seamlessly integrates these events via REST API calls. We will set up a basic go http server and connect it with the minio events. The HTTP server simply prints the request body as follows, package main import ( fmt io/ioutil net/http ) func hello ( w http . ResponseWriter , req * http . Request ) { body , err : = ioutil . ReadAll ( req . Body ) if err != nil { fmt . Printf ( %+v \\n , err ) return } fmt . Println ( string ( body )) fmt . Fprintf ( w , hello \\n ) } func main () { http . HandleFunc ( /hello , hello ) fmt . Println ( server is listening on 8090 ) http . ListenAndServe ( :8090 , nil ) } Deploy the HTTP server, kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/09-http-trigger/http-server.yaml Create a service to expose the http server kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/09-http-trigger/http-server-svc.yaml Either use Ingress, OpenShift Route or port-forwarding to expose the http server.. kubectl -n argo-events port-forward http-server-pod-name 8090:8090 Our goals is to seamlessly integrate Minio S3 bucket notifications with REST API server created in previous step. So, lets set up the Minio event-source available here . Don't create the sensor as we will be deploying it in next step. Create a sensor as follows, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/http-trigger.yaml Now, drop a file onto input bucket in Minio server. The sensor has triggered a http request to the http server. Take a look at the logs server is listening on 8090 { type : minio , bucket : input } Great!!! Request Payload In order to construct a request payload based on the event data, sensor offers payload field as a part of the HTP trigger. Let's examine a HTTP trigger, http: url: http://http-server.argo-events.svc:8090/hello payload: - src: dependencyName: test-dep dataKey: notification.0.s3.bucket.name dest: bucket - src: dependencyName: test-dep contextKey: type dest: type method: POST // GET, DELETE, POST, PUT, HEAD, etc. The payload contains the list of src which refers to the source event and dest which refers to destination key within result request payload. The payload declared above will generate a request payload like below, { type : type of event from event s context bucket : bucket name from event data } The above payload will be passed in the HTTP request. You can add however many number of src and dest under payload . Note : Take a look at Parameterization in order to understand how to extract particular key-value from event data. Parameterization Similar to other type of triggers, sensor offers parameterization for the HTTP trigger. Parameterization is specially useful when you want to define a generic trigger template in the sensor and populate values like URL, payload values on the fly. You can learn more about trigger parameterization here . Policy Trigger policy helps you determine the status of the HTTP request and decide whether to stop or continue sensor. To determine whether the HTTP request was successful or not, the HTTP trigger provides a Status policy. The Status holds a list of response statuses that are considered valid. http: url: http://http-server.argo-events.svc:8090/hello payload: - src: dependencyName: test-dep dataKey: notification.0s3.bucket.name dest: bucket - src: dependencyName: test-dep contextKey: type dest: type method: POST // GET, DELETE, POST, PUT, HEAD, etc. policy: status: allow: - 200 - 201 The above HTTP trigger will be treated successful only if the HTTP request returns with either 200 or 201 status. OpenFaas OpenFaas offers a simple way to spin up serverless functions. Lets see how we can leverage Argo Events HTTP trigger to invoke OpenFaas function. If you don't have OpenFaas installed, follow the instructions . Let's create a basic function. You can follow the steps to set up the function. package function import ( fmt ) // Handle a serverless request func Handle ( req [] byte ) string { return fmt . Sprintf ( Hello, Go. You said: %s , string ( req )) } Make sure the function pod is up and running. We are going to invoke OpenFaas function on a message on Redis Subscriber. Let's set up the Redis Database, Redis PubSub event-source as specified here . Do not create the Redis sensor, we are going to create it in next step. Let's create the sensor with OpenFaas trigger apiVersion : argoproj . io / v1alpha1 kind : Sensor metadata : name : redis - sensor spec : template : serviceAccountName : argo - events - sa dependencies : - name : test - dep eventSourceName : redis eventName : example subscription : http : port : 9300 triggers : - template : name : openfaas - trigger http : url : http :// gateway . openfaas . svc . cluster . local : 8080 /function/g ohash payload : - src : dependencyName : test - dep dest : bucket method : POST Publish a message on FOO channel using redis-cli . PUBLISH FOO hello As soon as you publish the message, the sensor will invoke the OpenFaas function gohash . Kubeless Similar to REST API calls, you can easily invoke Kubeless functions using HTTP trigger. If you don't have Kubeless installed, follow the installation . Lets create a basic function, def hello(event, context): print event return event[ data ] Make sure the function pod and service is created. Now, we are going to invoke the Kubeless function when a message is placed on a NATS queue. Let's set up the NATS event-source. Follow instructions for details. Do not create the NATS sensor, we are going to create it in next step. Let's create NATS sensor with HTTP trigger, apiVersion : argoproj . io / v1alpha1 kind : Sensor metadata : name : nats - sensor spec : template : serviceAccountName : argo - events - sa dependencies : - name : test - dep eventSourceName : nats eventName : example subscription : http : port : 9300 triggers : - template : name : kubeless - trigger http : serverURL : http :// hello . kubeless . svc . cluster . local : 8080 payload : - src : dependencyName : test - dep dataKey : body . first_name dest : first_name - src : dependencyName : test - dep dataKey : body . last_name dest : last_name method : POST Once event-source and sensor pod are up and running, dispatch a message on foo subject using nats client, go run main.go -s localhost foo { first_name : foo , last_name : bar } It will invoke Kubeless function hello , { event-time : None, extensions : { request : LocalRequest: POST http://hello.kubeless.svc.cluster.local:8080/ }, event-type : None, event-namespace : None, data : { first_name : foo , last_name : bar } , event-id : None} Other serverless frameworks Similar to OpenFaas and Kubeless invocation demonstrated above, you can easily trigger KNative, Nuclio, Fission functions using HTTP trigger.","title":"HTTP Trigger"},{"location":"triggers/http-trigger/#http-trigger","text":"Argo Events offers HTTP trigger which can easily invoke serverless functions like OpenFaas, Kubeless, Knative, Nuclio and make REST API calls.","title":"HTTP Trigger"},{"location":"triggers/http-trigger/#specification","text":"The HTTP trigger specification is available here .","title":"Specification"},{"location":"triggers/http-trigger/#rest-api-calls","text":"Consider a scenario where your REST API server needs to consume events from event-sources S3, GitHub, SQS etc. Usually, you'd end up writing the integration yourself in the server code, although server logic has nothing to do any of the event-sources. This is where Argo Events HTTP trigger can hel. The HTTP trigger takes the task of consuming events from event-sources away from API server and seamlessly integrates these events via REST API calls. We will set up a basic go http server and connect it with the minio events. The HTTP server simply prints the request body as follows, package main import ( fmt io/ioutil net/http ) func hello ( w http . ResponseWriter , req * http . Request ) { body , err : = ioutil . ReadAll ( req . Body ) if err != nil { fmt . Printf ( %+v \\n , err ) return } fmt . Println ( string ( body )) fmt . Fprintf ( w , hello \\n ) } func main () { http . HandleFunc ( /hello , hello ) fmt . Println ( server is listening on 8090 ) http . ListenAndServe ( :8090 , nil ) } Deploy the HTTP server, kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/09-http-trigger/http-server.yaml Create a service to expose the http server kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/09-http-trigger/http-server-svc.yaml Either use Ingress, OpenShift Route or port-forwarding to expose the http server.. kubectl -n argo-events port-forward http-server-pod-name 8090:8090 Our goals is to seamlessly integrate Minio S3 bucket notifications with REST API server created in previous step. So, lets set up the Minio event-source available here . Don't create the sensor as we will be deploying it in next step. Create a sensor as follows, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/http-trigger.yaml Now, drop a file onto input bucket in Minio server. The sensor has triggered a http request to the http server. Take a look at the logs server is listening on 8090 { type : minio , bucket : input } Great!!!","title":"REST API Calls"},{"location":"triggers/http-trigger/#request-payload","text":"In order to construct a request payload based on the event data, sensor offers payload field as a part of the HTP trigger. Let's examine a HTTP trigger, http: url: http://http-server.argo-events.svc:8090/hello payload: - src: dependencyName: test-dep dataKey: notification.0.s3.bucket.name dest: bucket - src: dependencyName: test-dep contextKey: type dest: type method: POST // GET, DELETE, POST, PUT, HEAD, etc. The payload contains the list of src which refers to the source event and dest which refers to destination key within result request payload. The payload declared above will generate a request payload like below, { type : type of event from event s context bucket : bucket name from event data } The above payload will be passed in the HTTP request. You can add however many number of src and dest under payload . Note : Take a look at Parameterization in order to understand how to extract particular key-value from event data.","title":"Request Payload"},{"location":"triggers/http-trigger/#parameterization","text":"Similar to other type of triggers, sensor offers parameterization for the HTTP trigger. Parameterization is specially useful when you want to define a generic trigger template in the sensor and populate values like URL, payload values on the fly. You can learn more about trigger parameterization here .","title":"Parameterization"},{"location":"triggers/http-trigger/#policy","text":"Trigger policy helps you determine the status of the HTTP request and decide whether to stop or continue sensor. To determine whether the HTTP request was successful or not, the HTTP trigger provides a Status policy. The Status holds a list of response statuses that are considered valid. http: url: http://http-server.argo-events.svc:8090/hello payload: - src: dependencyName: test-dep dataKey: notification.0s3.bucket.name dest: bucket - src: dependencyName: test-dep contextKey: type dest: type method: POST // GET, DELETE, POST, PUT, HEAD, etc. policy: status: allow: - 200 - 201 The above HTTP trigger will be treated successful only if the HTTP request returns with either 200 or 201 status.","title":"Policy"},{"location":"triggers/http-trigger/#openfaas","text":"OpenFaas offers a simple way to spin up serverless functions. Lets see how we can leverage Argo Events HTTP trigger to invoke OpenFaas function. If you don't have OpenFaas installed, follow the instructions . Let's create a basic function. You can follow the steps to set up the function. package function import ( fmt ) // Handle a serverless request func Handle ( req [] byte ) string { return fmt . Sprintf ( Hello, Go. You said: %s , string ( req )) } Make sure the function pod is up and running. We are going to invoke OpenFaas function on a message on Redis Subscriber. Let's set up the Redis Database, Redis PubSub event-source as specified here . Do not create the Redis sensor, we are going to create it in next step. Let's create the sensor with OpenFaas trigger apiVersion : argoproj . io / v1alpha1 kind : Sensor metadata : name : redis - sensor spec : template : serviceAccountName : argo - events - sa dependencies : - name : test - dep eventSourceName : redis eventName : example subscription : http : port : 9300 triggers : - template : name : openfaas - trigger http : url : http :// gateway . openfaas . svc . cluster . local : 8080 /function/g ohash payload : - src : dependencyName : test - dep dest : bucket method : POST Publish a message on FOO channel using redis-cli . PUBLISH FOO hello As soon as you publish the message, the sensor will invoke the OpenFaas function gohash .","title":"OpenFaas"},{"location":"triggers/http-trigger/#kubeless","text":"Similar to REST API calls, you can easily invoke Kubeless functions using HTTP trigger. If you don't have Kubeless installed, follow the installation . Lets create a basic function, def hello(event, context): print event return event[ data ] Make sure the function pod and service is created. Now, we are going to invoke the Kubeless function when a message is placed on a NATS queue. Let's set up the NATS event-source. Follow instructions for details. Do not create the NATS sensor, we are going to create it in next step. Let's create NATS sensor with HTTP trigger, apiVersion : argoproj . io / v1alpha1 kind : Sensor metadata : name : nats - sensor spec : template : serviceAccountName : argo - events - sa dependencies : - name : test - dep eventSourceName : nats eventName : example subscription : http : port : 9300 triggers : - template : name : kubeless - trigger http : serverURL : http :// hello . kubeless . svc . cluster . local : 8080 payload : - src : dependencyName : test - dep dataKey : body . first_name dest : first_name - src : dependencyName : test - dep dataKey : body . last_name dest : last_name method : POST Once event-source and sensor pod are up and running, dispatch a message on foo subject using nats client, go run main.go -s localhost foo { first_name : foo , last_name : bar } It will invoke Kubeless function hello , { event-time : None, extensions : { request : LocalRequest: POST http://hello.kubeless.svc.cluster.local:8080/ }, event-type : None, event-namespace : None, data : { first_name : foo , last_name : bar } , event-id : None}","title":"Kubeless"},{"location":"triggers/http-trigger/#other-serverless-frameworks","text":"Similar to OpenFaas and Kubeless invocation demonstrated above, you can easily trigger KNative, Nuclio, Fission functions using HTTP trigger.","title":"Other serverless frameworks"},{"location":"triggers/k8s-object-trigger/","text":"Kubernetes Object Trigger Apart from Argo workflow objects, the sensor lets you trigger standard Kubernetes objects such as Pod, Deployment, Job, CronJob, etc. Having the ability to trigger standard Kubernetes objects is quite powerful as provides an avenue to set up event-driven pipelines for existing workloads. Trigger a K8s Pod We will use webhook event-source and sensor to trigger a K8s pod. Lets set up a webhook event source to process incoming requests. kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/webhook.yaml To trigger a pod, we need to create a sensor as defined below, apiVersion : argoproj . io / v1alpha1 kind : Sensor metadata : name : webhook spec : template : serviceAccountName : argo - events - sa dependencies : - name : test - dep eventSourceName : webhook eventName : example subscription : http : port : 9300 triggers : - template : name : webhook - pod - trigger k8s : group : version : v1 resource : pods operation : create source : resource : apiVersion : v1 kind : Pod metadata : generateName : hello - world - spec : containers : - name : hello - container args : - hello-world command : - cowsay image : docker/whalesay:latest parameters : - src : dependencyName : test - dep dest : spec . containers . 0 . args . 0 The group , version and resource under k8s in the trigger template determines the type of K8s object. Change it accordingly if you want to trigger something else than a pod. Create the sensor, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/trigger-standard-k8s-resource.yaml Lets expose the webhook event-source pod using port-forward so that we can make a request to it. kubectl -n argo-events port-forward name-of-event-source-pod 12000:12000 Use either Curl or Postman to send a post request to the http://localhost:12000/example curl -d { message : ok } -H Content-Type: application/json -X POST http://localhost:12000/example Inspect the logs of the pod, you will something similar as below, _________________________________________ / { context :{ type : webhook , specVersi \\ | on : 0.3 , source : webhook , e | | ventID : 30306463666539362d346666642d34 | | 3336332d383861312d336538363333613564313 | | 932 , time : 2020-01-11T21:23:07.682961 | | Z , dataContentType : application/json | | , subject : example }, data : eyJoZWFkZ | | XIiOnsiQWNjZXB0IjpbIiovKiJdLCJDb250ZW50 | | LUxlbmd0aCI6WyIxOSJdLCJDb250ZW50LVR5cGU | | iOlsiYXBwbGljYXRpb24vanNvbiJdLCJVc2VyLU | | FnZW50IjpbImN1cmwvNy41NC4wIl19LCJib2R5I | \\ jp7Im1lc3NhZ2UiOiJoZXkhISJ9fQ== } / ----------------------------------------- \\ \\ \\ ## . ## ## ## == ## ## ## ## === / ___/ === ~~~ {~~ ~~~~ ~~~ ~~~~ ~~ ~ / ===- ~~~ \\______ o __/ \\ \\ __/ \\____\\______/ Operation You can specify the operation for the trigger using the operation key under triggers- template- k8s. Operation can be either, create : Creates the object if not available in K8s cluster. update : Updates the object. patch : Patches the object using given patch strategy. More info available at here . Parameterization Similar to other type of triggers, sensor offers parameterization for the K8s trigger. Parameterization is specially useful when you want to define a generic trigger template in the sensor and populate the K8s object values on the fly. You can learn more about trigger parameterization here . Policy Trigger policy helps you determine the status of the triggered K8s object and decide whether to stop or continue sensor. To determine whether the K8s object was successful or not, the K8s trigger provides a Resource Labels policy. The Resource Labels holds a list of labels which are checked against the triggered K8s object to determine the status of the object. # Policy to configure backoff and execution criteria for the trigger # Because the sensor is able to trigger any K8s resource, it determines the resource state by looking at the resource s labels. policy: k8s: # Backoff before checking the resource labels backoff: # Duration is the duration in nanoseconds duration: 1000000000 # 1 second # Duration is multiplied by factor each iteration factor: 2 # The amount of jitter applied each iteration jitter: 0.1 # Exit with error after these many steps steps: 5 # labels set on the resource decide if the resource has transitioned into the success state. labels: workflows.argoproj.io/phase: Succeeded # Determines whether trigger should be marked as failed if the backoff times out and sensor is still unable to decide the state of the trigger. # defaults to false errorOnBackoffTimeout: true Complete example is available here .","title":"Kubernetes Object Trigger"},{"location":"triggers/k8s-object-trigger/#kubernetes-object-trigger","text":"Apart from Argo workflow objects, the sensor lets you trigger standard Kubernetes objects such as Pod, Deployment, Job, CronJob, etc. Having the ability to trigger standard Kubernetes objects is quite powerful as provides an avenue to set up event-driven pipelines for existing workloads.","title":"Kubernetes Object Trigger"},{"location":"triggers/k8s-object-trigger/#trigger-a-k8s-pod","text":"We will use webhook event-source and sensor to trigger a K8s pod. Lets set up a webhook event source to process incoming requests. kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/webhook.yaml To trigger a pod, we need to create a sensor as defined below, apiVersion : argoproj . io / v1alpha1 kind : Sensor metadata : name : webhook spec : template : serviceAccountName : argo - events - sa dependencies : - name : test - dep eventSourceName : webhook eventName : example subscription : http : port : 9300 triggers : - template : name : webhook - pod - trigger k8s : group : version : v1 resource : pods operation : create source : resource : apiVersion : v1 kind : Pod metadata : generateName : hello - world - spec : containers : - name : hello - container args : - hello-world command : - cowsay image : docker/whalesay:latest parameters : - src : dependencyName : test - dep dest : spec . containers . 0 . args . 0 The group , version and resource under k8s in the trigger template determines the type of K8s object. Change it accordingly if you want to trigger something else than a pod. Create the sensor, kubectl apply -n argo-events -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/trigger-standard-k8s-resource.yaml Lets expose the webhook event-source pod using port-forward so that we can make a request to it. kubectl -n argo-events port-forward name-of-event-source-pod 12000:12000 Use either Curl or Postman to send a post request to the http://localhost:12000/example curl -d { message : ok } -H Content-Type: application/json -X POST http://localhost:12000/example Inspect the logs of the pod, you will something similar as below, _________________________________________ / { context :{ type : webhook , specVersi \\ | on : 0.3 , source : webhook , e | | ventID : 30306463666539362d346666642d34 | | 3336332d383861312d336538363333613564313 | | 932 , time : 2020-01-11T21:23:07.682961 | | Z , dataContentType : application/json | | , subject : example }, data : eyJoZWFkZ | | XIiOnsiQWNjZXB0IjpbIiovKiJdLCJDb250ZW50 | | LUxlbmd0aCI6WyIxOSJdLCJDb250ZW50LVR5cGU | | iOlsiYXBwbGljYXRpb24vanNvbiJdLCJVc2VyLU | | FnZW50IjpbImN1cmwvNy41NC4wIl19LCJib2R5I | \\ jp7Im1lc3NhZ2UiOiJoZXkhISJ9fQ== } / ----------------------------------------- \\ \\ \\ ## . ## ## ## == ## ## ## ## === / ___/ === ~~~ {~~ ~~~~ ~~~ ~~~~ ~~ ~ / ===- ~~~ \\______ o __/ \\ \\ __/ \\____\\______/","title":"Trigger a K8s Pod"},{"location":"triggers/k8s-object-trigger/#operation","text":"You can specify the operation for the trigger using the operation key under triggers- template- k8s. Operation can be either, create : Creates the object if not available in K8s cluster. update : Updates the object. patch : Patches the object using given patch strategy. More info available at here .","title":"Operation"},{"location":"triggers/k8s-object-trigger/#parameterization","text":"Similar to other type of triggers, sensor offers parameterization for the K8s trigger. Parameterization is specially useful when you want to define a generic trigger template in the sensor and populate the K8s object values on the fly. You can learn more about trigger parameterization here .","title":"Parameterization"},{"location":"triggers/k8s-object-trigger/#policy","text":"Trigger policy helps you determine the status of the triggered K8s object and decide whether to stop or continue sensor. To determine whether the K8s object was successful or not, the K8s trigger provides a Resource Labels policy. The Resource Labels holds a list of labels which are checked against the triggered K8s object to determine the status of the object. # Policy to configure backoff and execution criteria for the trigger # Because the sensor is able to trigger any K8s resource, it determines the resource state by looking at the resource s labels. policy: k8s: # Backoff before checking the resource labels backoff: # Duration is the duration in nanoseconds duration: 1000000000 # 1 second # Duration is multiplied by factor each iteration factor: 2 # The amount of jitter applied each iteration jitter: 0.1 # Exit with error after these many steps steps: 5 # labels set on the resource decide if the resource has transitioned into the success state. labels: workflows.argoproj.io/phase: Succeeded # Determines whether trigger should be marked as failed if the backoff times out and sensor is still unable to decide the state of the trigger. # defaults to false errorOnBackoffTimeout: true Complete example is available here .","title":"Policy"},{"location":"triggers/kafka-trigger/","text":"Kafka Trigger Kafka trigger allows sensor to publish events on Kafka topic. This trigger helps source the events from outside world into your messaging queues. Specification The Kafka trigger specification is available here . Walkthrough Consider a scenario where you are expecting a file drop onto a Minio bucket and want to place that event on a Kafka topic. Set up the Minio Event Source here . Do not create the Minio sensor, we are going to create it in next step. Lets create the sensor, apiVersion : argoproj . io / v1alpha1 kind : Sensor metadata : name : minio - sensor spec : template : serviceAccountName : argo - events - sa dependencies : - name : test - dep eventSourceName : minio eventName : example subscription : http : port : 9300 triggers : - template : name : kafka - trigger kafka : # Kafka URL url : kafka . argo - events . svc : 9092 # Name of the topic topic : minio - events # partition id partition : 0 payload : - src : dependencyName : test - dep dataKey : notification . 0 . s3 . object . key dest : fileName - src : dependencyName : test - dep dataKey : notification . 0 . s3 . bucket . name dest : bucket The Kafka message needs a body. In order to construct message based on the event data, sensor offers payload field as a part of the Kafka trigger. The payload contains the list of src which refers to the source event and dest which refers to destination key within result request payload. The payload declared above will generate a message body like below, { fileName : hello.txt // name/key of the object bucket : input // name of the bucket } Drop a file called hello.txt onto the bucket input and you will receive the message on Kafka topic","title":"Kafka Trigger"},{"location":"triggers/kafka-trigger/#kafka-trigger","text":"Kafka trigger allows sensor to publish events on Kafka topic. This trigger helps source the events from outside world into your messaging queues.","title":"Kafka Trigger"},{"location":"triggers/kafka-trigger/#specification","text":"The Kafka trigger specification is available here .","title":"Specification"},{"location":"triggers/kafka-trigger/#walkthrough","text":"Consider a scenario where you are expecting a file drop onto a Minio bucket and want to place that event on a Kafka topic. Set up the Minio Event Source here . Do not create the Minio sensor, we are going to create it in next step. Lets create the sensor, apiVersion : argoproj . io / v1alpha1 kind : Sensor metadata : name : minio - sensor spec : template : serviceAccountName : argo - events - sa dependencies : - name : test - dep eventSourceName : minio eventName : example subscription : http : port : 9300 triggers : - template : name : kafka - trigger kafka : # Kafka URL url : kafka . argo - events . svc : 9092 # Name of the topic topic : minio - events # partition id partition : 0 payload : - src : dependencyName : test - dep dataKey : notification . 0 . s3 . object . key dest : fileName - src : dependencyName : test - dep dataKey : notification . 0 . s3 . bucket . name dest : bucket The Kafka message needs a body. In order to construct message based on the event data, sensor offers payload field as a part of the Kafka trigger. The payload contains the list of src which refers to the source event and dest which refers to destination key within result request payload. The payload declared above will generate a message body like below, { fileName : hello.txt // name/key of the object bucket : input // name of the bucket } Drop a file called hello.txt onto the bucket input and you will receive the message on Kafka topic","title":"Walkthrough"},{"location":"triggers/nats-trigger/","text":"NATS Trigger NATS trigger allows sensor to publish events on NATS subjects. This trigger helps source the events from outside world into your messaging queues. Specification The NATS trigger specification is available here . Walkthrough Consider a scenario where you are expecting a file drop onto a Minio bucket and want to place that event on a NATS subject. Set up the Minio Event Source here . Do not create the Minio sensor, we are going to create it in next step. Lets create the sensor, apiVersion : argoproj . io / v1alpha1 kind : Sensor metadata : name : minio - sensor spec : template : serviceAccountName : argo - events - sa dependencies : - name : test - dep eventSourceName : minio eventName : example subscription : http : port : 9300 triggers : - template : name : nats - trigger nats : # NATS Server URL url : nats . argo - events . svc : 4222 # Name of the subject subject : minio - events payload : - src : dependencyName : test - dep dataKey : notification . 0 . s3 . object . key dest : fileName - src : dependencyName : test - dep dataKey : notification . 0 . s3 . bucket . name dest : bucket The NATS message needs a body. In order to construct message based on the event data, sensor offers payload field as a part of the NATS trigger. The payload contains the list of src which refers to the source event and dest which refers to destination key within result request payload. The payload declared above will generate a message body like below, { fileName : hello.txt // name/key of the object bucket : input // name of the bucket } If you are running NATS on local K8s cluster, make sure to port-forward to pod, kubectl -n argo-events port-forward nats-pod-name 4222:4222 Subscribe to the subject called minio-events . Refer the nats example to publish a message to the subject https://github.com/nats-io/go-nats-examples/tree/master/patterns/publish-subscribe. go run main.go -s localhost minio-events Drop a file called hello.txt onto the bucket input and you will receive the message on NATS subscriber as follows, [#1] Received on [minio-events]: { bucket : input , fileName : hello.txt }","title":"NATS Trigger"},{"location":"triggers/nats-trigger/#nats-trigger","text":"NATS trigger allows sensor to publish events on NATS subjects. This trigger helps source the events from outside world into your messaging queues.","title":"NATS Trigger"},{"location":"triggers/nats-trigger/#specification","text":"The NATS trigger specification is available here .","title":"Specification"},{"location":"triggers/nats-trigger/#walkthrough","text":"Consider a scenario where you are expecting a file drop onto a Minio bucket and want to place that event on a NATS subject. Set up the Minio Event Source here . Do not create the Minio sensor, we are going to create it in next step. Lets create the sensor, apiVersion : argoproj . io / v1alpha1 kind : Sensor metadata : name : minio - sensor spec : template : serviceAccountName : argo - events - sa dependencies : - name : test - dep eventSourceName : minio eventName : example subscription : http : port : 9300 triggers : - template : name : nats - trigger nats : # NATS Server URL url : nats . argo - events . svc : 4222 # Name of the subject subject : minio - events payload : - src : dependencyName : test - dep dataKey : notification . 0 . s3 . object . key dest : fileName - src : dependencyName : test - dep dataKey : notification . 0 . s3 . bucket . name dest : bucket The NATS message needs a body. In order to construct message based on the event data, sensor offers payload field as a part of the NATS trigger. The payload contains the list of src which refers to the source event and dest which refers to destination key within result request payload. The payload declared above will generate a message body like below, { fileName : hello.txt // name/key of the object bucket : input // name of the bucket } If you are running NATS on local K8s cluster, make sure to port-forward to pod, kubectl -n argo-events port-forward nats-pod-name 4222:4222 Subscribe to the subject called minio-events . Refer the nats example to publish a message to the subject https://github.com/nats-io/go-nats-examples/tree/master/patterns/publish-subscribe. go run main.go -s localhost minio-events Drop a file called hello.txt onto the bucket input and you will receive the message on NATS subscriber as follows, [#1] Received on [minio-events]: { bucket : input , fileName : hello.txt }","title":"Walkthrough"},{"location":"triggers/openwhisk-trigger/","text":"OpenWhisk Trigger OpenWhisk is a framework to run serverless workloads. It ships with its own event sources but their numbers are limited and it doesn't have support for circuits, parameterization, filtering, on-demand payload construction, etc that a sensor provides. Prerequisite OpenWhisk must be up and running. Setup Coming Soon...","title":"OpenWhisk Trigger"},{"location":"triggers/openwhisk-trigger/#openwhisk-trigger","text":"OpenWhisk is a framework to run serverless workloads. It ships with its own event sources but their numbers are limited and it doesn't have support for circuits, parameterization, filtering, on-demand payload construction, etc that a sensor provides.","title":"OpenWhisk Trigger"},{"location":"triggers/openwhisk-trigger/#prerequisite","text":"OpenWhisk must be up and running.","title":"Prerequisite"},{"location":"triggers/openwhisk-trigger/#setup","text":"Coming Soon...","title":"Setup"},{"location":"triggers/slack-trigger/","text":"Slack Trigger The Slack trigger is used to send a custom message to a desired Slack channel in a Slack workspace. The intended use is for notifications for a build pipeline, but can be used for any notification scenario. Prerequisite Deploy the eventbus in the namespace. Make sure to have a Slack workspace setup you wish to send a message to. Create a webhook event-source. kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/webhook.yaml Set up port-forwarding to expose the http server. We will use port-forwarding here. kubectl port-forward -n argo-events event-source-pod-name 12000:12000 Create a Slack App We need to create a Slack App which will send messages to your Slack Workspace. We will add OAuth Permissions and add the OAuth token to the k8s cluster via a secret. Create a Slack app by clicking Create New App at the Slack API Page . Name your app and choose your intended Slack Workspace Navigate to your app, then to Features OAuth Permissions Scroll down to Scopes and add the scopes channels:join , and chat:write Scroll to the top of the OAuth Permissions page and click Install App to Workspace and follow the install Wizard You should land back on the OAuth Permissions page. Copy your app's OAuth Access Token. This will allow the trigger to act on behalf of your newly created Slack app. Encode your OAuth token in base64. This can done easily with the command line echo -n YOUR-OAUTH-TOKEN | base64 Create a kubernetes secret file slack-secret.yaml with your OAuth token in the following format apiVersion : v1 kind : Secret metadata : name : slack - secret data : token : YOUR - BASE64 - ENCODED - OAUTH - TOKEN Apply the kubernetes secret kubectl -n argo-events apply -f slack-secret.yaml Slack Trigger We will set up a basic slack trigger and send a default message, and then a dynamic custom message. Create a sensor with Slack trigger. We will discuss the trigger details in the following sections. kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/slack-trigger.yaml Send a http request to the event-source-pod to fire the Slack trigger. curl -d { text : Hello, World! } -H Content-Type: application/json -X POST http://localhost:12000/example Note : The default slack-trigger will send the message \"hello world\" to the #general channel. You may change the default message and channel in slack-trigger.yaml under triggers.slack.channel and triggers.slack.message. Alternatively, you can dynamically determine the channel and message based on parameterization of your event. curl -d { channel : random , message : test message } -H Content-Type: application/json -X POST http://localhost:12000/example Great! But, how did the sensor use the event to customize the message and channel from the http request? We will see that in next section. Parameterization The slack trigger parameters have the following structure, parameters: - src: dependencyName: test-dep dataKey: body.channel dest: slack.channel - src: dependencyName: test-dep contextKey: body.message dest: slack.message The src is the source of event. It contains, dependencyName : name of the event dependency to extract the event from. dataKey : to extract a particular key-value from event's data. contextKey : to extract a particular key-value from event' context. The dest is the destination key within the result payload. So, the above trigger paramters will generate a request payload as, { channel : channel_to_send_message , message : message_to_send_to_channel } Note : If you define both the contextKey and dataKey within a paramter item, then the dataKey takes the precedence. You can create any paramater structure you want. To get more info on how to generate complex event payloads, take a look at this library . The complete specification of Slack trigger is available here .","title":"Slack Trigger"},{"location":"triggers/slack-trigger/#slack-trigger","text":"The Slack trigger is used to send a custom message to a desired Slack channel in a Slack workspace. The intended use is for notifications for a build pipeline, but can be used for any notification scenario.","title":"Slack Trigger"},{"location":"triggers/slack-trigger/#prerequisite","text":"Deploy the eventbus in the namespace. Make sure to have a Slack workspace setup you wish to send a message to. Create a webhook event-source. kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/webhook.yaml Set up port-forwarding to expose the http server. We will use port-forwarding here. kubectl port-forward -n argo-events event-source-pod-name 12000:12000","title":"Prerequisite"},{"location":"triggers/slack-trigger/#create-a-slack-app","text":"We need to create a Slack App which will send messages to your Slack Workspace. We will add OAuth Permissions and add the OAuth token to the k8s cluster via a secret. Create a Slack app by clicking Create New App at the Slack API Page . Name your app and choose your intended Slack Workspace Navigate to your app, then to Features OAuth Permissions Scroll down to Scopes and add the scopes channels:join , and chat:write Scroll to the top of the OAuth Permissions page and click Install App to Workspace and follow the install Wizard You should land back on the OAuth Permissions page. Copy your app's OAuth Access Token. This will allow the trigger to act on behalf of your newly created Slack app. Encode your OAuth token in base64. This can done easily with the command line echo -n YOUR-OAUTH-TOKEN | base64 Create a kubernetes secret file slack-secret.yaml with your OAuth token in the following format apiVersion : v1 kind : Secret metadata : name : slack - secret data : token : YOUR - BASE64 - ENCODED - OAUTH - TOKEN Apply the kubernetes secret kubectl -n argo-events apply -f slack-secret.yaml","title":"Create a Slack App"},{"location":"triggers/slack-trigger/#slack-trigger_1","text":"We will set up a basic slack trigger and send a default message, and then a dynamic custom message. Create a sensor with Slack trigger. We will discuss the trigger details in the following sections. kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/slack-trigger.yaml Send a http request to the event-source-pod to fire the Slack trigger. curl -d { text : Hello, World! } -H Content-Type: application/json -X POST http://localhost:12000/example Note : The default slack-trigger will send the message \"hello world\" to the #general channel. You may change the default message and channel in slack-trigger.yaml under triggers.slack.channel and triggers.slack.message. Alternatively, you can dynamically determine the channel and message based on parameterization of your event. curl -d { channel : random , message : test message } -H Content-Type: application/json -X POST http://localhost:12000/example Great! But, how did the sensor use the event to customize the message and channel from the http request? We will see that in next section.","title":"Slack Trigger"},{"location":"triggers/slack-trigger/#parameterization","text":"The slack trigger parameters have the following structure, parameters: - src: dependencyName: test-dep dataKey: body.channel dest: slack.channel - src: dependencyName: test-dep contextKey: body.message dest: slack.message The src is the source of event. It contains, dependencyName : name of the event dependency to extract the event from. dataKey : to extract a particular key-value from event's data. contextKey : to extract a particular key-value from event' context. The dest is the destination key within the result payload. So, the above trigger paramters will generate a request payload as, { channel : channel_to_send_message , message : message_to_send_to_channel } Note : If you define both the contextKey and dataKey within a paramter item, then the dataKey takes the precedence. You can create any paramater structure you want. To get more info on how to generate complex event payloads, take a look at this library . The complete specification of Slack trigger is available here .","title":"Parameterization"},{"location":"tutorials/01-introduction/","text":"Introduction In the tutorials, we will cover every aspect of Argo Events and demonstrate how you can leverage these features to build an event driven workflow pipeline. All the concepts you will learn in this tutorial and subsequent ones can be applied to any type of event-source. Prerequisites Follow the installation guide to set up the Argo Events. Make sure to configure Argo Workflow controller to listen to workflow objects created in argo-events namespace. Make sure to read the concepts behind eventbus , sensor , event source . Get Started We are going to set up a sensor and event-source for webhook. The goal is to trigger an Argo workflow upon a HTTP Post request. Let' set up the eventbus, kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/eventbus/native.yaml Create the webhook event source. kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/webhook.yaml Create the webhook sensor. kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/webhook.yaml If the commands are executed successfully, the eventbus, event-source and sensor pods will get created. You will also notice that a service is created for the event-source. Expose the event-source pod via Ingress, OpenShift Route or port forward to consume requests over HTTP. kubectl -n argo-events port-forward event-source-pod-name 12000:12000 Use either Curl or Postman to send a post request to the http://localhost:12000/example curl -d { message : this is my first webhook } -H Content-Type: application/json -X POST http://localhost:12000/example Now, you should see an Argo workflow being created. kubectl -n argo-events get wf Make sure the workflow pod ran successfully. _________________________________________ / { context :{ type : webhook , specversi \\ | on : 0.3 , source : webhook , id : | 38376665363064642d343336352d343035 | | 372d393766662d366234326130656232343 | | 337 , time : 2020-01-11T16:55:42.996636 | | Z , datacontenttype : application/json | | , subject : example }, data : eyJoZWFkZ | | XIiOnsiQWNjZXB0IjpbIiovKiJdLCJDb250ZW50 | | LUxlbmd0aCI6WyIzOCJdLCJDb250ZW50LVR5cGU | | iOlsiYXBwbGljYXRpb24vanNvbiJdLCJVc2VyLU | | FnZW50IjpbImN1cmwvNy41NC4wIl19LCJib2R5I | | jp7Im1lc3NhZ2UiOiJ0aGlzIGlzIG15IGZpcnN0 | \\ IHdlYmhvb2sifX0= } / ----------------------------------------- \\ \\ \\ ## . ## ## ## == ## ## ## ## === / ___/ === ~~~ {~~ ~~~~ ~~~ ~~~~ ~~ ~ / ===- ~~~ \\______ o __/ \\ \\ __/ \\____\\______/ Note: You will see the message printed in the workflow logs contains both the event context and data, with data being base64 encoded. In later sections, we will see how to extract particular key-value from event context or data and pass it to the workflow as arguments. Troubleshoot If you don't see the event-source and sensor pod in argo-events namespace, Make sure the correct Role and RoleBindings are applied to the service account and there are no errors in both event-source and sensor controller. Make sure the sensor controller configmap has namespace set to argo-events . Check the logs of event-source and sensor controller. Make sure the controllers have processed the event-source and sensor objects and there are no errors. Look for any error in event-source or sensor pod. Inspect the event-source, kubectl -n argo-events event-source-object-name -o yaml Inspect the sensor, kubectl -n argo-events sensor-object-name -o yaml and look for any errors within the Status . Raise an issue on GitHub or post a question on argo-events slack channel.","title":"Introduction"},{"location":"tutorials/01-introduction/#introduction","text":"In the tutorials, we will cover every aspect of Argo Events and demonstrate how you can leverage these features to build an event driven workflow pipeline. All the concepts you will learn in this tutorial and subsequent ones can be applied to any type of event-source.","title":"Introduction"},{"location":"tutorials/01-introduction/#prerequisites","text":"Follow the installation guide to set up the Argo Events. Make sure to configure Argo Workflow controller to listen to workflow objects created in argo-events namespace. Make sure to read the concepts behind eventbus , sensor , event source .","title":"Prerequisites"},{"location":"tutorials/01-introduction/#get-started","text":"We are going to set up a sensor and event-source for webhook. The goal is to trigger an Argo workflow upon a HTTP Post request. Let' set up the eventbus, kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/eventbus/native.yaml Create the webhook event source. kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/event-sources/webhook.yaml Create the webhook sensor. kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/sensors/webhook.yaml If the commands are executed successfully, the eventbus, event-source and sensor pods will get created. You will also notice that a service is created for the event-source. Expose the event-source pod via Ingress, OpenShift Route or port forward to consume requests over HTTP. kubectl -n argo-events port-forward event-source-pod-name 12000:12000 Use either Curl or Postman to send a post request to the http://localhost:12000/example curl -d { message : this is my first webhook } -H Content-Type: application/json -X POST http://localhost:12000/example Now, you should see an Argo workflow being created. kubectl -n argo-events get wf Make sure the workflow pod ran successfully. _________________________________________ / { context :{ type : webhook , specversi \\ | on : 0.3 , source : webhook , id : | 38376665363064642d343336352d343035 | | 372d393766662d366234326130656232343 | | 337 , time : 2020-01-11T16:55:42.996636 | | Z , datacontenttype : application/json | | , subject : example }, data : eyJoZWFkZ | | XIiOnsiQWNjZXB0IjpbIiovKiJdLCJDb250ZW50 | | LUxlbmd0aCI6WyIzOCJdLCJDb250ZW50LVR5cGU | | iOlsiYXBwbGljYXRpb24vanNvbiJdLCJVc2VyLU | | FnZW50IjpbImN1cmwvNy41NC4wIl19LCJib2R5I | | jp7Im1lc3NhZ2UiOiJ0aGlzIGlzIG15IGZpcnN0 | \\ IHdlYmhvb2sifX0= } / ----------------------------------------- \\ \\ \\ ## . ## ## ## == ## ## ## ## === / ___/ === ~~~ {~~ ~~~~ ~~~ ~~~~ ~~ ~ / ===- ~~~ \\______ o __/ \\ \\ __/ \\____\\______/ Note: You will see the message printed in the workflow logs contains both the event context and data, with data being base64 encoded. In later sections, we will see how to extract particular key-value from event context or data and pass it to the workflow as arguments.","title":"Get Started"},{"location":"tutorials/01-introduction/#troubleshoot","text":"If you don't see the event-source and sensor pod in argo-events namespace, Make sure the correct Role and RoleBindings are applied to the service account and there are no errors in both event-source and sensor controller. Make sure the sensor controller configmap has namespace set to argo-events . Check the logs of event-source and sensor controller. Make sure the controllers have processed the event-source and sensor objects and there are no errors. Look for any error in event-source or sensor pod. Inspect the event-source, kubectl -n argo-events event-source-object-name -o yaml Inspect the sensor, kubectl -n argo-events sensor-object-name -o yaml and look for any errors within the Status . Raise an issue on GitHub or post a question on argo-events slack channel.","title":"Troubleshoot"},{"location":"tutorials/02-parameterization/","text":"Parameterization In the previous section, we saw how to set up a basic webhook event-source and sensor. The trigger template had parameters set in the sensor object, and the workflow was able to print the event payload. In this tutorial, we will dig deeper into different types of parameterization, how to extract particular key-value from event payload and how to use default values if certain key is not available within event payload. Trigger Resource Parameterization If you take a closer look at the Sensor object, you will notice it contains a list of triggers. Each Trigger contains the template that defines the context of the trigger and actual resource that we expect the sensor to execute. In the previous section, the resource within the trigger template was an Argo workflow. This subsection deals with how to parameterize the resource within trigger template with the event payload. Prerequisites Make sure to have the basic webhook event-source and sensor set up. Follow the introduction tutorial if haven't done already. Webhook Event Payload Webhook event-source consumes events through HTTP requests and transforms them into CloudEvents. The structure of the event the Webhook sensor receives from the event-source over the eventbus looks like following, { context : { type : type_of_event_source , specversion : cloud_events_version , source : name_of_the_event_source , id : unique_event_id , time : event_time , datacontenttype : type_of_data , subject : name_of_the_configuration_within_event_source }, data : { header : {}, body : {}, } } Context : This is the CloudEvent context and it is populated by the event-source regardless of type of HTTP request. Data : Data contains following fields, Header : The header within event data contains the headers in the HTTP request that was dispatched to the event-source. The event-source extracts the headers from the request and put it in the the header within event data . Body : This is the request payload from the HTTP request. Event Context Now that we have an understanding of the structure of the event the webhook sensor receives from the event-source over the eventbus, lets see how we can use the event context to parameterize the Argo workflow. Update the Webhook Sensor and add the contextKey for the parameter at index 0. kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/02-parameterization/sensor-01.yaml Send a HTTP request to the event-source pod. curl -d { message : this is my first webhook } -H Content-Type: application/json -X POST http://localhost:12000/example Inspect the output of the Argo workflow that was created. argo logs name_of_the_workflow You will see the following output, _________ webhook --------- \\ \\ \\ ## . ## ## ## == ## ## ## ## === / ___/ === ~~~ {~~ ~~~~ ~~~ ~~~~ ~~ ~ / ===- ~~~ \\______ o __/ \\ \\ __/ \\____\\______/ We have successfully extracted the type key within the event context and parameterized the workflow to print the value of the type . Event Data Now, it is time to use the event data and parameterize the Argo workflow trigger. We will extract the message from request payload and get the Argo workflow to print the message. Update the Webhook Sensor and add the dataKey in the parameter at index 0. kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/02-parameterization/sensor-02.yaml Send a HTTP request to the event-source pod. curl -d { message : this is my first webhook } -H Content-Type: application/json -X POST http://localhost:12000/example Inspect the output of the Argo workflow that was created. argo logs name_of_the_workflow You will see the following output, __________________________ this is my first webhook -------------------------- \\ \\ \\ ## . ## ## ## == ## ## ## ## === / ___/ === ~~~ {~~ ~~~~ ~~~ ~~~~ ~~ ~ / ===- ~~~ \\______ o __/ \\ \\ __/ \\____\\______/ Yay!! The Argo workflow printed the message. You can add however many number of parameters to update the trigger resource on the fly. Note : If you define both the contextKey and dataKey within a parameter, then the dataKey takes the precedence. Default Values Each parameter comes with an option to configure the default value. This is specially important when the key you defined in the parameter doesn't exist in the event. Update the Webhook Sensor and add the value for the parameter at index 0. We will also update the dataKey to an unknown event key. kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/02-parameterization/sensor-03.yaml Send a HTTP request to the event-source pod. curl -d { message : this is my first webhook } -H Content-Type: application/json -X POST http://localhost:12000/example Inspect the output of the Argo workflow that was created. argo logs name_of_the_workflow You will see the following output, _______________________ wow! a default value. ----------------------- \\ \\ \\ ## . ## ## ## == ## ## ## ## === / ___/ === ~~~ {~~ ~~~~ ~~~ ~~~~ ~~ ~ / ===- ~~~ \\______ o __/ \\ \\ __/ \\____\\______/ Sprig Templates The sprig template exposed through contextTemplate and dataTemplate lets you alter the event context and event data before it gets applied to the trigger via parameters . Take a look at the example defined here , it contains the parameters as follows, parameters: # Retrieve the message key from the payload - src: dependencyName: test-dep dataTemplate: {{ .Input.body.message | title }} dest: spec.arguments.parameters.0.value # Title case the context subject - src: dependencyName: test-dep contextTemplate: {{ .Input.subject | title }} dest: spec.arguments.parameters.1.value # Retrieve the name key from the payload, remove all whitespace and lowercase it. - src: dependencyName: test-dep dataTemplate: {{ .Input.body.name | nospace | lower }} - dest: metadata.generateName operation: append Consider the event the sensor received has format like, { context : { type : type_of_event_source , specversion : cloud_events_version , source : name_of_the_event_source , id : unique_event_id , time : event_time , datacontenttype : type_of_data , subject : name_of_the_configuration_within_event_source }, data : { body : { name : foo bar , message : hello there!! }, } } The parameters are transformed as, The first parameter extracts the body.message from event data and applies title filter which basically capitalizes the first letter and replaces the spec.arguments.parameters.0.value . The second parameter extracts the subject from the event context and again applies title filter and replaces the spec.arguments.parameters.1.value . The third parameter extracts the body.name from the event data, applies nospace filter which removes all white spaces and then lower filter which lowercases the text and appends it to metadata.generateName . Send a curl request to event-source as follows, curl -d { name : foo bar , message : hello there!! } -H Content-Type: application/json -X POST http://localhost:12000/example and you will see an Argo workflow being sprung with name like webhook-foobar-xxxxx . Check the output of the workflow, it should print something like, ____________________________ Hello There!! from Example ---------------------------- \\ \\ \\ ## . ## ## ## == ## ## ## ## === / ___/ === ~~~ {~~ ~~~~ ~~~ ~~~~ ~~ ~ / ===- ~~~ \\______ o __/ \\ \\ __/ \\____\\______/ Operations Sometimes you need the ability to append or prepend a parameter value to an existing value in trigger resource. This is where the operation field within a parameter comes handy. Update the Webhook Sensor and add the operation in the parameter at index 0. We will prepend the message to an existing value. kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/02-parameterization/sensor-04.yaml Send a HTTP request to the event-source. curl -d { message : hey!! } -H Content-Type: application/json -X POST http://localhost:12000/example Inspect the output of the Argo workflow that was created. argo logs name_of_the_workflow You will see the following output, __________________ hey!!hello world ------------------ \\ \\ \\ ## . ## ## ## == ## ## ## ## === / ___/ === ~~~ {~~ ~~~~ ~~~ ~~~~ ~~ ~ / ===- ~~~ \\______ o __/ \\ \\ __/ \\____\\______/ Trigger Template Parameterization The parameterization you saw above deals with the trigger resource, but sometimes you need to parameterize the trigger template itself. This comes handy when you have the trigger resource stored on some external source like S3, Git, etc. and you need to replace the url of the source on the fly in trigger template. Imagine a scenario where you want to parameterize the parameters of trigger to parameterize the trigger resource. What?... The sensor you have been using in this tutorial has one parameter defined in the trigger resource under k8s . We will parameterize that parameter by applying a parameter at the trigger template level. Update the Webhook Sensor and add parameters at trigger level. kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/02-parameterization/sensor-05.yaml Send a HTTP request to the event-source. curl -d { dependencyName : test-dep , dataKey : body.message , dest : spec.arguments.parameters.0.value , message : amazing!! } -H Content-Type: application/json -X POST http://localhost:12000/example Inspect the output of the Argo workflow that was created. argo logs name_of_the_workflow You will see the following output, ___________ amazing!! ----------- \\ \\ \\ ## . ## ## ## == ## ## ## ## === / ___/ === ~~~ {~~ ~~~~ ~~~ ~~~~ ~~ ~ / ===- ~~~ \\______ o __/ \\ \\ __/ \\____\\______/ Great!! You have now learned how to apply parameters at trigger resource and template level. Keep in mind that you can apply default values and operations like prepend and append for trigger template parameters as well.","title":"Parameterization"},{"location":"tutorials/02-parameterization/#parameterization","text":"In the previous section, we saw how to set up a basic webhook event-source and sensor. The trigger template had parameters set in the sensor object, and the workflow was able to print the event payload. In this tutorial, we will dig deeper into different types of parameterization, how to extract particular key-value from event payload and how to use default values if certain key is not available within event payload.","title":"Parameterization"},{"location":"tutorials/02-parameterization/#trigger-resource-parameterization","text":"If you take a closer look at the Sensor object, you will notice it contains a list of triggers. Each Trigger contains the template that defines the context of the trigger and actual resource that we expect the sensor to execute. In the previous section, the resource within the trigger template was an Argo workflow. This subsection deals with how to parameterize the resource within trigger template with the event payload.","title":"Trigger Resource Parameterization"},{"location":"tutorials/02-parameterization/#prerequisites","text":"Make sure to have the basic webhook event-source and sensor set up. Follow the introduction tutorial if haven't done already.","title":"Prerequisites"},{"location":"tutorials/02-parameterization/#webhook-event-payload","text":"Webhook event-source consumes events through HTTP requests and transforms them into CloudEvents. The structure of the event the Webhook sensor receives from the event-source over the eventbus looks like following, { context : { type : type_of_event_source , specversion : cloud_events_version , source : name_of_the_event_source , id : unique_event_id , time : event_time , datacontenttype : type_of_data , subject : name_of_the_configuration_within_event_source }, data : { header : {}, body : {}, } } Context : This is the CloudEvent context and it is populated by the event-source regardless of type of HTTP request. Data : Data contains following fields, Header : The header within event data contains the headers in the HTTP request that was dispatched to the event-source. The event-source extracts the headers from the request and put it in the the header within event data . Body : This is the request payload from the HTTP request.","title":"Webhook Event Payload"},{"location":"tutorials/02-parameterization/#event-context","text":"Now that we have an understanding of the structure of the event the webhook sensor receives from the event-source over the eventbus, lets see how we can use the event context to parameterize the Argo workflow. Update the Webhook Sensor and add the contextKey for the parameter at index 0. kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/02-parameterization/sensor-01.yaml Send a HTTP request to the event-source pod. curl -d { message : this is my first webhook } -H Content-Type: application/json -X POST http://localhost:12000/example Inspect the output of the Argo workflow that was created. argo logs name_of_the_workflow You will see the following output, _________ webhook --------- \\ \\ \\ ## . ## ## ## == ## ## ## ## === / ___/ === ~~~ {~~ ~~~~ ~~~ ~~~~ ~~ ~ / ===- ~~~ \\______ o __/ \\ \\ __/ \\____\\______/ We have successfully extracted the type key within the event context and parameterized the workflow to print the value of the type .","title":"Event Context"},{"location":"tutorials/02-parameterization/#event-data","text":"Now, it is time to use the event data and parameterize the Argo workflow trigger. We will extract the message from request payload and get the Argo workflow to print the message. Update the Webhook Sensor and add the dataKey in the parameter at index 0. kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/02-parameterization/sensor-02.yaml Send a HTTP request to the event-source pod. curl -d { message : this is my first webhook } -H Content-Type: application/json -X POST http://localhost:12000/example Inspect the output of the Argo workflow that was created. argo logs name_of_the_workflow You will see the following output, __________________________ this is my first webhook -------------------------- \\ \\ \\ ## . ## ## ## == ## ## ## ## === / ___/ === ~~~ {~~ ~~~~ ~~~ ~~~~ ~~ ~ / ===- ~~~ \\______ o __/ \\ \\ __/ \\____\\______/ Yay!! The Argo workflow printed the message. You can add however many number of parameters to update the trigger resource on the fly. Note : If you define both the contextKey and dataKey within a parameter, then the dataKey takes the precedence.","title":"Event Data"},{"location":"tutorials/02-parameterization/#default-values","text":"Each parameter comes with an option to configure the default value. This is specially important when the key you defined in the parameter doesn't exist in the event. Update the Webhook Sensor and add the value for the parameter at index 0. We will also update the dataKey to an unknown event key. kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/02-parameterization/sensor-03.yaml Send a HTTP request to the event-source pod. curl -d { message : this is my first webhook } -H Content-Type: application/json -X POST http://localhost:12000/example Inspect the output of the Argo workflow that was created. argo logs name_of_the_workflow You will see the following output, _______________________ wow! a default value. ----------------------- \\ \\ \\ ## . ## ## ## == ## ## ## ## === / ___/ === ~~~ {~~ ~~~~ ~~~ ~~~~ ~~ ~ / ===- ~~~ \\______ o __/ \\ \\ __/ \\____\\______/","title":"Default Values"},{"location":"tutorials/02-parameterization/#sprig-templates","text":"The sprig template exposed through contextTemplate and dataTemplate lets you alter the event context and event data before it gets applied to the trigger via parameters . Take a look at the example defined here , it contains the parameters as follows, parameters: # Retrieve the message key from the payload - src: dependencyName: test-dep dataTemplate: {{ .Input.body.message | title }} dest: spec.arguments.parameters.0.value # Title case the context subject - src: dependencyName: test-dep contextTemplate: {{ .Input.subject | title }} dest: spec.arguments.parameters.1.value # Retrieve the name key from the payload, remove all whitespace and lowercase it. - src: dependencyName: test-dep dataTemplate: {{ .Input.body.name | nospace | lower }} - dest: metadata.generateName operation: append Consider the event the sensor received has format like, { context : { type : type_of_event_source , specversion : cloud_events_version , source : name_of_the_event_source , id : unique_event_id , time : event_time , datacontenttype : type_of_data , subject : name_of_the_configuration_within_event_source }, data : { body : { name : foo bar , message : hello there!! }, } } The parameters are transformed as, The first parameter extracts the body.message from event data and applies title filter which basically capitalizes the first letter and replaces the spec.arguments.parameters.0.value . The second parameter extracts the subject from the event context and again applies title filter and replaces the spec.arguments.parameters.1.value . The third parameter extracts the body.name from the event data, applies nospace filter which removes all white spaces and then lower filter which lowercases the text and appends it to metadata.generateName . Send a curl request to event-source as follows, curl -d { name : foo bar , message : hello there!! } -H Content-Type: application/json -X POST http://localhost:12000/example and you will see an Argo workflow being sprung with name like webhook-foobar-xxxxx . Check the output of the workflow, it should print something like, ____________________________ Hello There!! from Example ---------------------------- \\ \\ \\ ## . ## ## ## == ## ## ## ## === / ___/ === ~~~ {~~ ~~~~ ~~~ ~~~~ ~~ ~ / ===- ~~~ \\______ o __/ \\ \\ __/ \\____\\______/","title":"Sprig Templates"},{"location":"tutorials/02-parameterization/#operations","text":"Sometimes you need the ability to append or prepend a parameter value to an existing value in trigger resource. This is where the operation field within a parameter comes handy. Update the Webhook Sensor and add the operation in the parameter at index 0. We will prepend the message to an existing value. kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/02-parameterization/sensor-04.yaml Send a HTTP request to the event-source. curl -d { message : hey!! } -H Content-Type: application/json -X POST http://localhost:12000/example Inspect the output of the Argo workflow that was created. argo logs name_of_the_workflow You will see the following output, __________________ hey!!hello world ------------------ \\ \\ \\ ## . ## ## ## == ## ## ## ## === / ___/ === ~~~ {~~ ~~~~ ~~~ ~~~~ ~~ ~ / ===- ~~~ \\______ o __/ \\ \\ __/ \\____\\______/","title":"Operations"},{"location":"tutorials/02-parameterization/#trigger-template-parameterization","text":"The parameterization you saw above deals with the trigger resource, but sometimes you need to parameterize the trigger template itself. This comes handy when you have the trigger resource stored on some external source like S3, Git, etc. and you need to replace the url of the source on the fly in trigger template. Imagine a scenario where you want to parameterize the parameters of trigger to parameterize the trigger resource. What?... The sensor you have been using in this tutorial has one parameter defined in the trigger resource under k8s . We will parameterize that parameter by applying a parameter at the trigger template level. Update the Webhook Sensor and add parameters at trigger level. kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/02-parameterization/sensor-05.yaml Send a HTTP request to the event-source. curl -d { dependencyName : test-dep , dataKey : body.message , dest : spec.arguments.parameters.0.value , message : amazing!! } -H Content-Type: application/json -X POST http://localhost:12000/example Inspect the output of the Argo workflow that was created. argo logs name_of_the_workflow You will see the following output, ___________ amazing!! ----------- \\ \\ \\ ## . ## ## ## == ## ## ## ## === / ___/ === ~~~ {~~ ~~~~ ~~~ ~~~~ ~~ ~ / ===- ~~~ \\______ o __/ \\ \\ __/ \\____\\______/ Great!! You have now learned how to apply parameters at trigger resource and template level. Keep in mind that you can apply default values and operations like prepend and append for trigger template parameters as well.","title":"Trigger Template Parameterization"},{"location":"tutorials/03-trigger-sources/","text":"Trigger Sources A trigger source is the source of trigger resource. It can be either external source such as Git , S3 , K8s Configmap , File , any valid URL that hosts the resource or an internal resource which is defined in the sensor object itself like Inline or Resource . In the previous sections, you have been dealing with the Resource trigger source. In this tutorial, we will explore other trigger sources. Prerequisites The Webhook event-source is already set up. Git Git trigger source refers to K8s trigger refers to the K8s resource stored in Git. The specification for the Git source is available here . In order to fetch data from git, you need to set up the private SSH key in sensor. If you don't have ssh keys available, create them following this guide Create a K8s secret that holds the SSH keys kubectl -n argo-events create secret generic git-ssh --from-file=key=.ssh/ YOUR_SSH_KEY_FILE_NAME Create a K8s secret that holds known hosts. kubectl -n argo-events create secret generic git-known-hosts --from-file=ssh_known_hosts=.ssh/known_hosts Create a sensor with the git trigger source and refer it to the hello world workflow stored on the Argo Git project kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/03-trigger-sources/sensor-git.yaml Use either Curl or Postman to send a post request to the http://localhost:12000/example curl -d { message : ok } -H Content-Type: application/json -X POST http://localhost:12000/example Now, you should see an Argo workflow being created. kubectl -n argo-events get wf S3 You can refer to the K8s resource stored on S3 complaint store as the trigger source. For this tutorial, lets set up a minio server which is S3 compliant store. Create a K8s secret called artifacts-minio that holds your minio access key and secret key. The access key must be stored under accesskey key and secret key must be stored under secretkey . Follow steps described here to set up the minio server. Make sure a service is available to expose the minio server. Create a bucket called workflows and store a basic hello world Argo workflow with key name hello-world.yaml . Create the sensor with trigger source as S3. kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/03-trigger-sources/sensor-minio.yaml Use either Curl or Postman to send a post request to the http://localhost:12000/example curl -d { message : ok } -H Content-Type: application/json -X POST http://localhost:12000/example Now, you should see an Argo workflow being created. kubectl -n argo-events get wf K8s Configmap K8s configmap can be treated as trigger source if needed. Lets create a configmap called trigger-store . kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/03-trigger-sources/trigger-store.yaml Create a sensor with trigger source as configmap and refer it to the trigger-store . kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/03-trigger-sources/sensor-cm.yaml Use either Curl or Postman to send a post request to the http://localhost:12000/example curl -d { message : ok } -H Content-Type: application/json -X POST http://localhost:12000/example Now, you should see an Argo workflow being created. kubectl -n argo-events get wf File URL File and URL trigger sources are pretty self explanatory. The example sensors are available under examples/sensors folder.","title":"Trigger Sources"},{"location":"tutorials/03-trigger-sources/#trigger-sources","text":"A trigger source is the source of trigger resource. It can be either external source such as Git , S3 , K8s Configmap , File , any valid URL that hosts the resource or an internal resource which is defined in the sensor object itself like Inline or Resource . In the previous sections, you have been dealing with the Resource trigger source. In this tutorial, we will explore other trigger sources.","title":"Trigger Sources"},{"location":"tutorials/03-trigger-sources/#prerequisites","text":"The Webhook event-source is already set up.","title":"Prerequisites"},{"location":"tutorials/03-trigger-sources/#git","text":"Git trigger source refers to K8s trigger refers to the K8s resource stored in Git. The specification for the Git source is available here . In order to fetch data from git, you need to set up the private SSH key in sensor. If you don't have ssh keys available, create them following this guide Create a K8s secret that holds the SSH keys kubectl -n argo-events create secret generic git-ssh --from-file=key=.ssh/ YOUR_SSH_KEY_FILE_NAME Create a K8s secret that holds known hosts. kubectl -n argo-events create secret generic git-known-hosts --from-file=ssh_known_hosts=.ssh/known_hosts Create a sensor with the git trigger source and refer it to the hello world workflow stored on the Argo Git project kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/03-trigger-sources/sensor-git.yaml Use either Curl or Postman to send a post request to the http://localhost:12000/example curl -d { message : ok } -H Content-Type: application/json -X POST http://localhost:12000/example Now, you should see an Argo workflow being created. kubectl -n argo-events get wf","title":"Git"},{"location":"tutorials/03-trigger-sources/#s3","text":"You can refer to the K8s resource stored on S3 complaint store as the trigger source. For this tutorial, lets set up a minio server which is S3 compliant store. Create a K8s secret called artifacts-minio that holds your minio access key and secret key. The access key must be stored under accesskey key and secret key must be stored under secretkey . Follow steps described here to set up the minio server. Make sure a service is available to expose the minio server. Create a bucket called workflows and store a basic hello world Argo workflow with key name hello-world.yaml . Create the sensor with trigger source as S3. kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/03-trigger-sources/sensor-minio.yaml Use either Curl or Postman to send a post request to the http://localhost:12000/example curl -d { message : ok } -H Content-Type: application/json -X POST http://localhost:12000/example Now, you should see an Argo workflow being created. kubectl -n argo-events get wf","title":"S3"},{"location":"tutorials/03-trigger-sources/#k8s-configmap","text":"K8s configmap can be treated as trigger source if needed. Lets create a configmap called trigger-store . kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/03-trigger-sources/trigger-store.yaml Create a sensor with trigger source as configmap and refer it to the trigger-store . kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/03-trigger-sources/sensor-cm.yaml Use either Curl or Postman to send a post request to the http://localhost:12000/example curl -d { message : ok } -H Content-Type: application/json -X POST http://localhost:12000/example Now, you should see an Argo workflow being created. kubectl -n argo-events get wf","title":"K8s Configmap"},{"location":"tutorials/03-trigger-sources/#file-url","text":"File and URL trigger sources are pretty self explanatory. The example sensors are available under examples/sensors folder.","title":"File &amp; URL"},{"location":"tutorials/04-standard-k8s-resources/","text":"Trigger Standard K8s Resources In the previous sections, you saw how to trigger the Argo workflows. In this tutorial, you will see how to trigger Pod and Deployment. Note: You can trigger any standard Kubernetes object. Having the ability to trigger standard Kubernetes resources is quite powerful as provides an avenue to set up pipelines for existing workloads. Prerequisites Make sure that argo-events-sa service account has necessary permissions to create the Kubernetes resource of your choice. The Webhook event-source is already set up. Pod Create a sensor with K8s trigger. Pay close attention to the group , version and kind keys within the trigger resource. These keys determine the type of kubernetes object. You will notice that the group key is empty, that means we want to use core group. For any other groups, you need to specify the group key. kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/04-standard-k8s-resources/sensor-pod.yaml Use either Curl or Postman to send a post request to the http://localhost:12000/example curl -d { message : ok } -H Content-Type: application/json -X POST http://localhost:12000/example Now, you should see a pod being created. kubectl -n argo-events get po Output _________________________________________ / { context :{ type : webhook , specVersi \\ | on : 0.3 , source : webhook , e | | ventID : 30306463666539362d346666642d34 | | 3336332d383861312d336538363333613564313 | | 932 , time : 2020-01-11T21:23:07.682961 | | Z , dataContentType : application/json | | , subject : example }, data : eyJoZWFkZ | | XIiOnsiQWNjZXB0IjpbIiovKiJdLCJDb250ZW50 | | LUxlbmd0aCI6WyIxOSJdLCJDb250ZW50LVR5cGU | | iOlsiYXBwbGljYXRpb24vanNvbiJdLCJVc2VyLU | | FnZW50IjpbImN1cmwvNy41NC4wIl19LCJib2R5I | \\ jp7Im1lc3NhZ2UiOiJoZXkhISJ9fQ== } / ----------------------------------------- \\ \\ \\ ## . ## ## ## == ## ## ## ## === / ___/ === ~~~ {~~ ~~~~ ~~~ ~~~~ ~~ ~ / ===- ~~~ \\______ o __/ \\ \\ __/ \\____\\______/ Deployment Lets create a sensor with a K8s deployment as trigger. kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/04-standard-k8s-resources/sensor-deployment.yaml Use either Curl or Postman to send a post request to the http://localhost:12000/example curl -d { message : ok } -H Content-Type: application/json -X POST http://localhost:12000/example Now, you should see a deployment being created. Get the corresponding pod. kubectl -n argo-events get deployments Output _________________________________________ / { context :{ type : webhook , specVersi \\ | on : 0.3 , source : webhook , e | | ventID : 30306463666539362d346666642d34 | | 3336332d383861312d336538363333613564313 | | 932 , time : 2020-01-11T21:23:07.682961 | | Z , dataContentType : application/json | | , subject : example }, data : eyJoZWFkZ | | XIiOnsiQWNjZXB0IjpbIiovKiJdLCJDb250ZW50 | | LUxlbmd0aCI6WyIxOSJdLCJDb250ZW50LVR5cGU | | iOlsiYXBwbGljYXRpb24vanNvbiJdLCJVc2VyLU | | FnZW50IjpbImN1cmwvNy41NC4wIl19LCJib2R5I | \\ jp7Im1lc3NhZ2UiOiJoZXkhISJ9fQ== } / ----------------------------------------- \\ \\ \\ ## . ## ## ## == ## ## ## ## === / ___/ === ~~~ {~~ ~~~~ ~~~ ~~~~ ~~ ~ / ===- ~~~ \\______ o __/ \\ \\ __/ \\____\\______/","title":"Trigger Standard K8s Resources"},{"location":"tutorials/04-standard-k8s-resources/#trigger-standard-k8s-resources","text":"In the previous sections, you saw how to trigger the Argo workflows. In this tutorial, you will see how to trigger Pod and Deployment. Note: You can trigger any standard Kubernetes object. Having the ability to trigger standard Kubernetes resources is quite powerful as provides an avenue to set up pipelines for existing workloads.","title":"Trigger Standard K8s Resources"},{"location":"tutorials/04-standard-k8s-resources/#prerequisites","text":"Make sure that argo-events-sa service account has necessary permissions to create the Kubernetes resource of your choice. The Webhook event-source is already set up.","title":"Prerequisites"},{"location":"tutorials/04-standard-k8s-resources/#pod","text":"Create a sensor with K8s trigger. Pay close attention to the group , version and kind keys within the trigger resource. These keys determine the type of kubernetes object. You will notice that the group key is empty, that means we want to use core group. For any other groups, you need to specify the group key. kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/04-standard-k8s-resources/sensor-pod.yaml Use either Curl or Postman to send a post request to the http://localhost:12000/example curl -d { message : ok } -H Content-Type: application/json -X POST http://localhost:12000/example Now, you should see a pod being created. kubectl -n argo-events get po Output _________________________________________ / { context :{ type : webhook , specVersi \\ | on : 0.3 , source : webhook , e | | ventID : 30306463666539362d346666642d34 | | 3336332d383861312d336538363333613564313 | | 932 , time : 2020-01-11T21:23:07.682961 | | Z , dataContentType : application/json | | , subject : example }, data : eyJoZWFkZ | | XIiOnsiQWNjZXB0IjpbIiovKiJdLCJDb250ZW50 | | LUxlbmd0aCI6WyIxOSJdLCJDb250ZW50LVR5cGU | | iOlsiYXBwbGljYXRpb24vanNvbiJdLCJVc2VyLU | | FnZW50IjpbImN1cmwvNy41NC4wIl19LCJib2R5I | \\ jp7Im1lc3NhZ2UiOiJoZXkhISJ9fQ== } / ----------------------------------------- \\ \\ \\ ## . ## ## ## == ## ## ## ## === / ___/ === ~~~ {~~ ~~~~ ~~~ ~~~~ ~~ ~ / ===- ~~~ \\______ o __/ \\ \\ __/ \\____\\______/","title":"Pod"},{"location":"tutorials/04-standard-k8s-resources/#deployment","text":"Lets create a sensor with a K8s deployment as trigger. kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/04-standard-k8s-resources/sensor-deployment.yaml Use either Curl or Postman to send a post request to the http://localhost:12000/example curl -d { message : ok } -H Content-Type: application/json -X POST http://localhost:12000/example Now, you should see a deployment being created. Get the corresponding pod. kubectl -n argo-events get deployments Output _________________________________________ / { context :{ type : webhook , specVersi \\ | on : 0.3 , source : webhook , e | | ventID : 30306463666539362d346666642d34 | | 3336332d383861312d336538363333613564313 | | 932 , time : 2020-01-11T21:23:07.682961 | | Z , dataContentType : application/json | | , subject : example }, data : eyJoZWFkZ | | XIiOnsiQWNjZXB0IjpbIiovKiJdLCJDb250ZW50 | | LUxlbmd0aCI6WyIxOSJdLCJDb250ZW50LVR5cGU | | iOlsiYXBwbGljYXRpb24vanNvbiJdLCJVc2VyLU | | FnZW50IjpbImN1cmwvNy41NC4wIl19LCJib2R5I | \\ jp7Im1lc3NhZ2UiOiJoZXkhISJ9fQ== } / ----------------------------------------- \\ \\ \\ ## . ## ## ## == ## ## ## ## === / ___/ === ~~~ {~~ ~~~~ ~~~ ~~~~ ~~ ~ / ===- ~~~ \\______ o __/ \\ \\ __/ \\____\\______/","title":"Deployment"},{"location":"tutorials/05-trigger-custom-resources/","text":"Trigger Custom Resources Take a look at Build Your Own Trigger to customize the sensor.","title":"Trigger Custom Resources"},{"location":"tutorials/05-trigger-custom-resources/#trigger-custom-resources","text":"Take a look at Build Your Own Trigger to customize the sensor.","title":"Trigger Custom Resources"},{"location":"tutorials/06-circuit-and-switch/","text":"Circuit and Switch In the previous sections, you have been dealing with just a single dependency. But, in many cases, you want to wait for multiple events to occur and then trigger a resource which means you need a mechanism to determine which triggers to execute based on set of different event dependencies. This mechanism is supported through Circuit and Switch . Note : Whenever you define multiple dependencies in a sensor, the sensor applies a AND operation, meaning, it will wait for all dependencies to resolve before it executes triggers. Circuit and Switch can modify that behavior. Prerequisite Minio server must be set up in the argo-events namespace with a bucket called test and it should be available at minio-service.argo-events:9000 . Circuit A circuit is a boolean expression. To create a circuit, you just need to define event dependencies in groups, and the sensor will apply the circuit logic on those groups. If the logic results in true value, the sensor will execute the triggers else it won't. Switch A switch is the conditional execution gate for a trigger. Consider a scenario where you have a Webhook and Minio event-source, and you want to trigger an Argo workflow if the sensor receives an event from the Webhook event-source, but, another workflow if it receives an event from the Minio event-source. Create the webhook event-source and event-source. The event-source listens to HTTP requests on port 12000 kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/05-circuit-and-switches/webhook-event-source.yaml Create the minio event-source. The event-source listens to events of type PUT and DELETE for objects in bucket test . kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/05-circuit-and-switches/minio-event-source.yaml Make sure there are no errors in any of the event-sources. Let's create the sensor. If you take a closer look at the trigger templates, you will notice that it contains switch key with all condition, meaning, execute this trigger when every group defined in all is resolved. In the sensor definition, there is only one group under all in both trigger templates. So, as soon as the group is resolved, the corresponding trigger will be executed. kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/06-circuit-and-switches/sensor-01.yaml Send a HTTP request to Webhook event-source, curl -d { message : this is my first webhook } -H Content-Type: application/json -X POST http://localhost:12000/example You will notice an Argo worklfow with name group-1-xxxx is created with following output, __________________________ this is my first webhook -------------------------- \\ \\ \\ ## . ## ## ## == ## ## ## ## === / ___/ === ~~~ {~~ ~~~~ ~~~ ~~~~ ~~ ~ / ===- ~~~ \\______ o __/ \\ \\ __/ \\____\\______/ Now, lets generate a Minio event so that we can run group-2-xxxx workflow. Drop a file onto test bucket. The workflow that will get created will print the name of the bucket as follows, ______ test ------ \\ \\ \\ ## . ## ## ## == ## ## ## ## === / ___/ === ~~~ {~~ ~~~~ ~~~ ~~~~ ~~ ~ / ===- ~~~ \\______ o __/ \\ \\ __/ \\____\\______/ Great!! You have now learned how to use a circuit and switch . Lets update the sensor with a trigger that waits for both groups to resolve. This is the normal sensor behavior if circuit is not defined. kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/06-circuit-and-switches/sensor-02.yaml Send a HTTP request and perform a file drop on Minio bucket as done above. You should following output, _______________________________ this is my first webhook test ------------------------------- \\ \\ \\ ## . ## ## ## == ## ## ## ## === / ___/ === ~~~ {~~ ~~~~ ~~~ ~~~~ ~~ ~ / ===- ~~~ \\______ o __/ \\ \\ __/ \\____\\______/","title":"Circuit and Switch"},{"location":"tutorials/06-circuit-and-switch/#circuit-and-switch","text":"In the previous sections, you have been dealing with just a single dependency. But, in many cases, you want to wait for multiple events to occur and then trigger a resource which means you need a mechanism to determine which triggers to execute based on set of different event dependencies. This mechanism is supported through Circuit and Switch . Note : Whenever you define multiple dependencies in a sensor, the sensor applies a AND operation, meaning, it will wait for all dependencies to resolve before it executes triggers. Circuit and Switch can modify that behavior.","title":"Circuit and Switch"},{"location":"tutorials/06-circuit-and-switch/#prerequisite","text":"Minio server must be set up in the argo-events namespace with a bucket called test and it should be available at minio-service.argo-events:9000 .","title":"Prerequisite"},{"location":"tutorials/06-circuit-and-switch/#circuit","text":"A circuit is a boolean expression. To create a circuit, you just need to define event dependencies in groups, and the sensor will apply the circuit logic on those groups. If the logic results in true value, the sensor will execute the triggers else it won't.","title":"Circuit"},{"location":"tutorials/06-circuit-and-switch/#switch","text":"A switch is the conditional execution gate for a trigger. Consider a scenario where you have a Webhook and Minio event-source, and you want to trigger an Argo workflow if the sensor receives an event from the Webhook event-source, but, another workflow if it receives an event from the Minio event-source. Create the webhook event-source and event-source. The event-source listens to HTTP requests on port 12000 kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/05-circuit-and-switches/webhook-event-source.yaml Create the minio event-source. The event-source listens to events of type PUT and DELETE for objects in bucket test . kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/05-circuit-and-switches/minio-event-source.yaml Make sure there are no errors in any of the event-sources. Let's create the sensor. If you take a closer look at the trigger templates, you will notice that it contains switch key with all condition, meaning, execute this trigger when every group defined in all is resolved. In the sensor definition, there is only one group under all in both trigger templates. So, as soon as the group is resolved, the corresponding trigger will be executed. kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/06-circuit-and-switches/sensor-01.yaml Send a HTTP request to Webhook event-source, curl -d { message : this is my first webhook } -H Content-Type: application/json -X POST http://localhost:12000/example You will notice an Argo worklfow with name group-1-xxxx is created with following output, __________________________ this is my first webhook -------------------------- \\ \\ \\ ## . ## ## ## == ## ## ## ## === / ___/ === ~~~ {~~ ~~~~ ~~~ ~~~~ ~~ ~ / ===- ~~~ \\______ o __/ \\ \\ __/ \\____\\______/ Now, lets generate a Minio event so that we can run group-2-xxxx workflow. Drop a file onto test bucket. The workflow that will get created will print the name of the bucket as follows, ______ test ------ \\ \\ \\ ## . ## ## ## == ## ## ## ## === / ___/ === ~~~ {~~ ~~~~ ~~~ ~~~~ ~~ ~ / ===- ~~~ \\______ o __/ \\ \\ __/ \\____\\______/ Great!! You have now learned how to use a circuit and switch . Lets update the sensor with a trigger that waits for both groups to resolve. This is the normal sensor behavior if circuit is not defined. kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/06-circuit-and-switches/sensor-02.yaml Send a HTTP request and perform a file drop on Minio bucket as done above. You should following output, _______________________________ this is my first webhook test ------------------------------- \\ \\ \\ ## . ## ## ## == ## ## ## ## === / ___/ === ~~~ {~~ ~~~~ ~~~ ~~~~ ~~ ~ / ===- ~~~ \\______ o __/ \\ \\ __/ \\____\\______/","title":"Switch"},{"location":"tutorials/07-filters/","text":"Filters In the previous sections, you have seen how to trigger an Argo workflow based on events. In this tutorial, you will learn how to apply filters on event data and context. Filters provide a powerful mechanism to apply constraints on the events in order to determine a validity. Argo Events offers 3 types of filters: Data Filter Context Filter Time Filter Prerequisite Webhook event-source must be set up. Data Filter Data filter as the name suggests are applied on the event data. A CloudEvent from Webhook event-source has payload structure as, { context : { type : type_of_event_source , specversion : cloud_events_version , source : name_of_the_event_source , id : unique_event_id , time : event_time , datacontenttype : type_of_data , subject : name_of_the_configuration_within_event_source }, data : { header : {}, body : {}, } } Data Filter are applied on data within the payload. We will make a simple HTTP request to webhook event-source with request data as {\"message\":\"this is my first webhook\"} and apply data filter on message . A data filter has following fields, data: - path: path_within_event_data type: types_of_the_data value: - list_of_possible_values Comparator The data filter offers comparator \u201c =\u201d, \u201c \u201d, \u201c=\u201d, \u201c \u201d, or \u201c =\u201d. e.g., filters: name: data-filter data: - path: body.value type: number comparator: value: - 50.0 Note : If data type is a string , then you can pass either an exact value or a regex. If data types is bool or float, then you need to pass the exact value. Lets create a webhook sensor with data filter. kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/07-filters/sensor-data-filters.yaml Send a HTTP request to event-source curl -d { message : this is my first webhook } -H Content-Type: application/json -X POST http://localhost:12000/example You will notice that the sensor logs prints the event is invalid as the sensor expects for either hello or hey as the value of body.message . Send a valid HTTP request to event-source curl -d { message : hello } -H Content-Type: application/json -X POST http://localhost:12000/example Watch for a workflow with name data-workflow-xxxx . Context Filter Similar to the data filter, you can apply a filter on the context of the event. Change the subscriber in the webhook event-source to point it to context-filter sensor's URL. Lets create a webhook sensor with context filter. kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/07-filters/sensor-context-filter.yaml Send a HTTP request to event-source curl -d { message : this is my first webhook } -H Content-Type: application/json -X POST http://localhost:12000/example You will notice that the sensor logs prints the event is invalid as the sensor expects for either custom-webhook as the value of the source . Time Filter You can also use time filter, which is applied on event time. It filters out events that occur outside the specified time range, so it is specially helpful when you need to make sure an event occurs between a certain time-frame. Time filter takes a start and stop time in HH:MM:SS format in UTC. If stop is smaller than start , the stop time is treated as next day of start . Note that start is inclusive while stop is exclusive. The diagrams below illustlate these behavior. An example of time filter is available under examples/sensors . if start stop : event time must be in [start, stop) 00:00:00 00:00:00 00:00:00 \u2503 start stop \u2503 start stop \u2503 \u2500\u2538\u2500\u2500\u2500\u2500\u2500\u25cf\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25cb\u2500\u2500\u2500\u2500\u2500\u2538\u2500\u2500\u2500\u2500\u2500\u25cf\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25cb\u2500\u2500\u2500\u2500\u2500\u2538\u2500 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 OK \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 OK \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f if stop start : event time must be in [start, stop@Next day) (this is equivalent to: event time must be in [00:00:00, stop) || [start, 00:00:00@Next day) ) 00:00:00 00:00:00 00:00:00 \u2503 stop start \u2503 stop start \u2503 \u2500\u2538\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25cb\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25cf\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2538\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25cb\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25cf\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2538\u2500 \u2500\u2500\u2500 OK \u2500\u2500\u2500\u2500\u2500\u2500\u256f \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 OK \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f \u2570\u2500\u2500\u2500\u2500\u2500\u2500 OK \u2500\u2500\u2500","title":"Filters"},{"location":"tutorials/07-filters/#filters","text":"In the previous sections, you have seen how to trigger an Argo workflow based on events. In this tutorial, you will learn how to apply filters on event data and context. Filters provide a powerful mechanism to apply constraints on the events in order to determine a validity. Argo Events offers 3 types of filters: Data Filter Context Filter Time Filter","title":"Filters"},{"location":"tutorials/07-filters/#prerequisite","text":"Webhook event-source must be set up.","title":"Prerequisite"},{"location":"tutorials/07-filters/#data-filter","text":"Data filter as the name suggests are applied on the event data. A CloudEvent from Webhook event-source has payload structure as, { context : { type : type_of_event_source , specversion : cloud_events_version , source : name_of_the_event_source , id : unique_event_id , time : event_time , datacontenttype : type_of_data , subject : name_of_the_configuration_within_event_source }, data : { header : {}, body : {}, } } Data Filter are applied on data within the payload. We will make a simple HTTP request to webhook event-source with request data as {\"message\":\"this is my first webhook\"} and apply data filter on message . A data filter has following fields, data: - path: path_within_event_data type: types_of_the_data value: - list_of_possible_values","title":"Data Filter"},{"location":"tutorials/07-filters/#comparator","text":"The data filter offers comparator \u201c =\u201d, \u201c \u201d, \u201c=\u201d, \u201c \u201d, or \u201c =\u201d. e.g., filters: name: data-filter data: - path: body.value type: number comparator: value: - 50.0 Note : If data type is a string , then you can pass either an exact value or a regex. If data types is bool or float, then you need to pass the exact value. Lets create a webhook sensor with data filter. kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/07-filters/sensor-data-filters.yaml Send a HTTP request to event-source curl -d { message : this is my first webhook } -H Content-Type: application/json -X POST http://localhost:12000/example You will notice that the sensor logs prints the event is invalid as the sensor expects for either hello or hey as the value of body.message . Send a valid HTTP request to event-source curl -d { message : hello } -H Content-Type: application/json -X POST http://localhost:12000/example Watch for a workflow with name data-workflow-xxxx .","title":"Comparator"},{"location":"tutorials/07-filters/#context-filter","text":"Similar to the data filter, you can apply a filter on the context of the event. Change the subscriber in the webhook event-source to point it to context-filter sensor's URL. Lets create a webhook sensor with context filter. kubectl -n argo-events apply -f https://raw.githubusercontent.com/argoproj/argo-events/stable/examples/tutorials/07-filters/sensor-context-filter.yaml Send a HTTP request to event-source curl -d { message : this is my first webhook } -H Content-Type: application/json -X POST http://localhost:12000/example You will notice that the sensor logs prints the event is invalid as the sensor expects for either custom-webhook as the value of the source .","title":"Context Filter"},{"location":"tutorials/07-filters/#time-filter","text":"You can also use time filter, which is applied on event time. It filters out events that occur outside the specified time range, so it is specially helpful when you need to make sure an event occurs between a certain time-frame. Time filter takes a start and stop time in HH:MM:SS format in UTC. If stop is smaller than start , the stop time is treated as next day of start . Note that start is inclusive while stop is exclusive. The diagrams below illustlate these behavior. An example of time filter is available under examples/sensors . if start stop : event time must be in [start, stop) 00:00:00 00:00:00 00:00:00 \u2503 start stop \u2503 start stop \u2503 \u2500\u2538\u2500\u2500\u2500\u2500\u2500\u25cf\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25cb\u2500\u2500\u2500\u2500\u2500\u2538\u2500\u2500\u2500\u2500\u2500\u25cf\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25cb\u2500\u2500\u2500\u2500\u2500\u2538\u2500 \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 OK \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 OK \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f if stop start : event time must be in [start, stop@Next day) (this is equivalent to: event time must be in [00:00:00, stop) || [start, 00:00:00@Next day) ) 00:00:00 00:00:00 00:00:00 \u2503 stop start \u2503 stop start \u2503 \u2500\u2538\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25cb\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25cf\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2538\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25cb\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25cf\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2538\u2500 \u2500\u2500\u2500 OK \u2500\u2500\u2500\u2500\u2500\u2500\u256f \u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 OK \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f \u2570\u2500\u2500\u2500\u2500\u2500\u2500 OK \u2500\u2500\u2500","title":"Time Filter"},{"location":"tutorials/08-policy/","text":"Policy A policy for a trigger determines whether the trigger resulted in success or failure. Currently, Argo Events supports 2 types of policies: Policy based on the K8s resource labels. Policy based on the response status for triggers like HTTP request, AWS Lambda, etc. Resource Labels Policy This type of policy determines whether trigger completed successfully based on the labels set on the trigger resource. Consider a sensor which has an Argo workflow as the trigger. When an Argo workflow completes successfully, the workflow controller sets a label on the resource as workflows.argoproj.io/completed: 'true' . So, in order for sensor to determine whether the trigger workflow completed successfully, you just need to set the policy labels as workflows.argoproj.io/completed: 'true' under trigger template. In addition to labels, you can also define a backoff and option to error out if sensor is unable to determine status of the trigger after the backoff completes. Check out the specification of resource labels policy here . Status Policy For triggers like HTTP request or AWS Lambda, you can apply the Status Policy to determine the trigger status. The Status Policy supports list of expected response statuses. If the status of the HTTP request or Lamda is within the statuses defined in the policy, then the trigger is considered successful. Complete specification is available here .","title":"Policy"},{"location":"tutorials/08-policy/#policy","text":"A policy for a trigger determines whether the trigger resulted in success or failure. Currently, Argo Events supports 2 types of policies: Policy based on the K8s resource labels. Policy based on the response status for triggers like HTTP request, AWS Lambda, etc.","title":"Policy"},{"location":"tutorials/08-policy/#resource-labels-policy","text":"This type of policy determines whether trigger completed successfully based on the labels set on the trigger resource. Consider a sensor which has an Argo workflow as the trigger. When an Argo workflow completes successfully, the workflow controller sets a label on the resource as workflows.argoproj.io/completed: 'true' . So, in order for sensor to determine whether the trigger workflow completed successfully, you just need to set the policy labels as workflows.argoproj.io/completed: 'true' under trigger template. In addition to labels, you can also define a backoff and option to error out if sensor is unable to determine status of the trigger after the backoff completes. Check out the specification of resource labels policy here .","title":"Resource Labels Policy"},{"location":"tutorials/08-policy/#status-policy","text":"For triggers like HTTP request or AWS Lambda, you can apply the Status Policy to determine the trigger status. The Status Policy supports list of expected response statuses. If the status of the HTTP request or Lamda is within the statuses defined in the policy, then the trigger is considered successful. Complete specification is available here .","title":"Status Policy"},{"location":"tutorials/09-service-account/","text":"Service Account for EventSources Most of the event-sources can be run with a service account with no roles associated, expect Resource event-source. You need to associate the get , list and watch permissions for the resource being watched, and assign that role to the service account. Service Account for Triggers Based on the type of trigger, it's a good practice to create a service account with minimum set of roles to execute it. The sensor examples use argo-events-sa service account to execute all types of triggers, but it is has more permissions than needed ,and you may want to limit those permissions based on your use-case. K8s Resource Trigger To execute Argo workflow trigger, make sure to grant create permission for workflows to the service account. To trigger a any other K8s resource, make sure to grant create permission for that resource. AWS Lambda, HTTP, Slack and OpenWhisk Trigger These triggers may need access to secrets for access tokens/auth related configuration. Make sure to grant get and list permissions for the secret resource. NATS and Kafka Triggers For NATS and Kafka, you don't need any K8s role associated with the service account.","title":"09 service account"},{"location":"tutorials/09-service-account/#service-account-for-eventsources","text":"Most of the event-sources can be run with a service account with no roles associated, expect Resource event-source. You need to associate the get , list and watch permissions for the resource being watched, and assign that role to the service account.","title":"Service Account for EventSources"},{"location":"tutorials/09-service-account/#service-account-for-triggers","text":"Based on the type of trigger, it's a good practice to create a service account with minimum set of roles to execute it. The sensor examples use argo-events-sa service account to execute all types of triggers, but it is has more permissions than needed ,and you may want to limit those permissions based on your use-case.","title":"Service Account for Triggers"},{"location":"tutorials/09-service-account/#k8s-resource-trigger","text":"To execute Argo workflow trigger, make sure to grant create permission for workflows to the service account. To trigger a any other K8s resource, make sure to grant create permission for that resource.","title":"K8s Resource Trigger"},{"location":"tutorials/09-service-account/#aws-lambda-http-slack-and-openwhisk-trigger","text":"These triggers may need access to secrets for access tokens/auth related configuration. Make sure to grant get and list permissions for the secret resource.","title":"AWS Lambda, HTTP, Slack and OpenWhisk Trigger"},{"location":"tutorials/09-service-account/#nats-and-kafka-triggers","text":"For NATS and Kafka, you don't need any K8s role associated with the service account.","title":"NATS and Kafka Triggers"}]}